{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series, concat, qcut, cut\n",
    "from scipy.special import xlogy\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_score(y, y_pred, weight=None, power=0, agg='sum'):\n",
    "    \"\"\"Function for Deviance evaluation.\n",
    "    Args:\n",
    "        y: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        weight: Weights for weighted metric.\n",
    "        power:\n",
    "        agg: Function to calculate deviance ['sum', 'mean'] or callable are supported.\n",
    "    Returns:\n",
    "        float, value of the Poisson deviance.\n",
    "    \"\"\"\n",
    "    dict_func = {'sum': np.sum, 'mean': np.mean}\n",
    "    func = dict_func[agg] if agg in ['sum', 'mean'] else agg if callable(agg) else None\n",
    "    if func is None:\n",
    "        raise ValueError\n",
    "    weight = 1 if weight is None else weight\n",
    "    if str(power).lower() in [\"normal\", \"gaussian\", \"0\"]:\n",
    "        return func(weight * np.power(y - y_pred, 2))\n",
    "    elif str(power).lower() in [\"poisson\", \"1\"]:\n",
    "        return func(2 * weight * (xlogy(y, y / y_pred) - (y - y_pred)))\n",
    "    elif str(power).lower() in [\"gamma\", \"2\"]:\n",
    "        return func(2 * weight * (np.log(y_pred / y) + y / y_pred - 1))\n",
    "    elif isinstance(power, str) or (0 < power < 1):\n",
    "        raise Exception(f\"power={power} is not supported.\")\n",
    "    else:\n",
    "        return func(\n",
    "            2\n",
    "            * weight\n",
    "            * (\n",
    "                np.power(np.max(y, 0), 2 - power) / ((1 - power) * (2 - power))\n",
    "                - (y * np.power(y_pred, 1 - power)) / (1 - power)\n",
    "                + (np.power(y_pred, 2 - power)) / (2 - power)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_poisson(y, y_pred, weight=None, agg='sum'):\n",
    "    \"\"\"Function for Poisson Deviance evaluation.\n",
    "    Args:\n",
    "        y: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        weight: Weights for weighted metric.\n",
    "        agg: Function to calculate deviance ['sum', 'mean'] or callable are supported.\n",
    "    Returns:\n",
    "        float, value of the Poisson deviance.\n",
    "    \"\"\"\n",
    "    return deviance_score(y, y_pred, weight=weight, power=1, agg=agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_gamma(y, y_pred, weight=None, agg='sum'):\n",
    "    \"\"\"Function for Gamma Deviance evaluation.\n",
    "    Args:\n",
    "        y: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        weight: Weights for weighted metric.\n",
    "        agg: Function to calculate deviance ['sum', 'mean'] or callable are supported.\n",
    "    Returns:\n",
    "        float, value of the Gamma deviance.\n",
    "    \"\"\"\n",
    "    return deviance_score(y, y_pred, weight=weight, power=2, agg=agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_explained(y, y_pred, weight=None, power=0):\n",
    "    \"\"\"Function for Pseudo R^2 (Deviance explained) evaluation.\n",
    "    Args:\n",
    "        y: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        weight: Weights for weighted metric.\n",
    "        power: Power for deviance calculation.\n",
    "    Returns:\n",
    "        float, value of the Pseudo R^2.\n",
    "    \"\"\"\n",
    "    dev = deviance_score(y, y_pred, weight=weight, power=power)\n",
    "    dev0 = deviance_score(y, np.repeat(np.mean(y), len(y)), weight=weight, power=power)\n",
    "    return 1 - dev / dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_explained_poisson(y, y_pred, weight=None):\n",
    "    \"\"\"Function for Pseudo R^2 (Deviance explained) evaluation for Poisson model.\n",
    "    Args:\n",
    "        y: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        weight: Weights for weighted metric.\n",
    "    Returns:\n",
    "        float, value of the Pseudo R^2.\n",
    "    \"\"\"\n",
    "    return deviance_explained(y, y_pred, weight=weight, power=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviance_explained_gamma(y, y_pred, weight=None):\n",
    "    \"\"\"Function for Pseudo R^2 (Deviance explained) evaluation for Gamma model.\n",
    "    Args:\n",
    "        y: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        weight: Weights for weighted metric.\n",
    "    Returns:\n",
    "        float, value of the Pseudo R^2.\n",
    "    \"\"\"\n",
    "    return deviance_explained(y, y_pred, weight=weight, power=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inforamtion_value_woe(data, target, bins=10, cat_thresh=10, detail=False):\n",
    "    \"\"\"Function for Information value and Weight of Evidence computation.\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame with data to compute IV and WoE.\n",
    "        target (str or pd.Series): Target variable to compute IV and WoE.\n",
    "        bins (int, optional): Number of bins for WoE calculation for continuous variables.\n",
    "        cat_thresh (int, optional): Maximum number of categories for non-binned WoE calculation.\n",
    "        detail (bool, optional):  Whether to return detailed results DataFrame or not. Short by default.\n",
    "    Returns:\n",
    "        pd.DataFrame, DataFrame containing the data on Information Value (depends on detail argument).\n",
    "    \"\"\"\n",
    "    detailed_result, short_result = DataFrame(), DataFrame()\n",
    "    target = target.name if isinstance(target, Series) else target\n",
    "    cols = data.columns\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars])) > cat_thresh):\n",
    "            binned_x = qcut(data[ivars], bins, duplicates='drop')\n",
    "            d0 = DataFrame({'x': binned_x, 'y': data[target]})\n",
    "        else:\n",
    "            d0 = DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = ['Cutoff', 'N', 'Events']\n",
    "        d['% of Events'] = np.maximum(d['Events'], 0.5) / d['Events'].sum()\n",
    "        d['Non-Events'] = d['N'] - d['Events']\n",
    "        d['% of Non-Events'] = np.maximum(d['Non-Events'], 0.5) / d['Non-Events'].sum()\n",
    "        d['WoE'] = np.log(d['% of Events'] / d['% of Non-Events'])\n",
    "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
    "        d.insert(loc=0, column='Variable', value=ivars)\n",
    "        temp = DataFrame({\"Variable\": [ivars], \"IV\": [d['IV'].sum()]}, columns=[\"Variable\", \"IV\"])\n",
    "        detailed_result = concat([detailed_result, temp], axis=0)\n",
    "        short_result = concat([short_result, d], axis=0)\n",
    "    return short_result if detail else detailed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_curve(y_true, y_pred, exposure):\n",
    "    \"\"\"Calculating lorenz curve and Gini coefficient.\n",
    "    Args:\n",
    "        y_true: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        exposure: Array with corresponding exposure\n",
    "    Returns: cumulated_samples, cumulated_claim_amount, -minus_gini_coef\n",
    "    \"\"\"\n",
    "    true, pred = np.asarray(y_true), np.asarray(y_pred)\n",
    "    exp = np.asarray(exposure)\n",
    "    ranking = np.argsort(-pred)\n",
    "    ranked_exposure, ranked_pure_premium = exp[ranking], true[ranking]\n",
    "    cumulated_claim_amount = np.cumsum(ranked_pure_premium * ranked_exposure)\n",
    "    cumulated_claim_amount /= cumulated_claim_amount[-1]\n",
    "    cumulated_samples = np.linspace(0, 1, len(cumulated_claim_amount))\n",
    "    minus_gini_coef = 1 - 2 * auc(cumulated_samples, cumulated_claim_amount)\n",
    "    return cumulated_samples, cumulated_claim_amount, -minus_gini_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_curve(y_true, y_pred, exposure, step=1, figsize=(10, 6)):\n",
    "    \"\"\"Plot gains curve and calculate Gini coefficient. Mostly making use of\n",
    "    https://scikit-learn.org/stable/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html.\n",
    "    Args:\n",
    "        y_true: Array with target variable.\n",
    "        y_pred: Array with predictions.\n",
    "        exposure: Array with corresponding exposure\n",
    "        step: Integer value which determines the increment between data indexes on which the gain curve will be\n",
    "         evaluated.\n",
    "        figsize: Tuple corresponding to matplotlib figsize.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title('Gains curve')\n",
    "    plt.xlabel('Fraction of policyholders\\n (ordered by model from riskiest to safest)')\n",
    "    plt.ylabel('Fraction of total claim amount')\n",
    "    y_true = y_true[::step]\n\n",
    "    # Random Baseline\n",
    "    plt.plot([0, 1], [0, 1], c='red', linestyle='--', linewidth=0.5, label='Random Baseline')\n\n",
    "    # Ideal Model\n",
    "    cumul_samples, cumul_claim_amt, gini = lorenz_curve(y_true, y_true, exposure)\n",
    "    plt.plot(\n",
    "        cumul_samples,\n",
    "        cumul_claim_amt,\n",
    "        c='black',\n",
    "        linestyle='-.',\n",
    "        linewidth=0.5,\n",
    "        label='Ideal Model (Gini: {:.3f})'.format(gini),\n",
    "    )\n\n",
    "    # Fitted Models\n",
    "    if isinstance(y_pred, list):\n",
    "        names = [i for i in range(len(y_pred))]\n",
    "        y_pred = [pred[::step] for pred in y_pred]\n",
    "    elif isinstance(y_pred, DataFrame):\n",
    "        names = y_pred.columns.tolist()\n",
    "        y_pred = [y_pred[col].values[::step] for col in y_pred.columns]\n",
    "    else:\n",
    "        names = y_pred.name if (isinstance(y_pred, Series) and y_pred.name is not None) else '0'\n",
    "        y_pred = y_pred[::step]\n",
    "    if isinstance(y_pred, list):\n",
    "        for i in range(len(y_pred)):\n",
    "            cumul_samples, cumul_claim_amt, gini = lorenz_curve(y_true, y_pred[i], exposure)\n",
    "            plt.plot(cumul_samples, cumul_claim_amt, label='Model {} (Gini: {:.3f})'.format(names[i], gini))\n",
    "    else:\n",
    "        cumul_samples, cumul_claim_amt, gini = lorenz_curve(y_true, y_pred, exposure)\n",
    "        plt.plot(cumul_samples, cumul_claim_amt, label='Model {} (Gini: {:.3f})'.format(names, gini))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_score(predict, column, lift_type='groupby', q=10, output=False, reference='mean', kind='line', show=True):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        predict:\n",
    "        column:\n",
    "        lift_type:\n",
    "        q:\n",
    "        output:\n",
    "        reference:\n",
    "        kind:\n",
    "        show:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    df = concat([column.reset_index(drop=True), Series(predict, name='Predict').reset_index(drop=True)], axis=1)\n",
    "    if lift_type == 'groupby':\n",
    "        pass\n",
    "    elif lift_type == 'quantile':\n",
    "        df[column.name] = qcut(column, q=q).reset_index(drop=True)\n",
    "    else:\n",
    "        raise Exception\n",
    "    if reference == 'mean':\n",
    "        df = df.groupby(column.name).mean() / np.mean(predict)\n",
    "    elif reference == 'min':\n",
    "        df = df.groupby(column.name).mean() / df.groupby(column.name).mean().min()\n",
    "    elif reference == 'max':\n",
    "        df = df.groupby(column.name).mean() / df.groupby(column.name).mean().max()\n",
    "    else:\n",
    "        raise Exception\n",
    "    if kind == 'bar':\n",
    "        plt.bar(df.index.astype(str), height=df['Predict'])\n",
    "    else:\n",
    "        plt.plot(df.index.astype(str), df['Predict'])\n",
    "    plt.title('Lift Metrics')\n",
    "    plt.xlabel(column.name)\n",
    "    plt.ylabel('Lift Score')\n",
    "    plt.xticks(rotation=90)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if output:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_index(scoring_variable, dev, oot, index='psi', binning_method='quantile', bins=10, detail=True):\n",
    "    \"\"\"Calculation of Population Stability Index or Characteristic Stability Index.\n",
    "    Based on https://www.lexjansen.com/wuss/2017/47_Final_Paper_PDF.pdf,\n",
    "    https://www.listendata.com/2015/05/population-stability-index.html and\n",
    "    https://towardsdatascience.com/psi-and-csi-top-2-model-monitoring-metrics-924a2540bed8.\n",
    "    Args:\n",
    "        scoring_variable (str): The name of the variable with respect to which the index will be calculated.\n",
    "        dev (pandas.DataFrame): The dataset containing `scoring_variable` on which the model was developed.\n",
    "        oot (pandas.DataFrame): The out-of-time dataset containing `scoring_variable`.\n",
    "        index (str): The type of stability index: Polulation (psi) or Characteristic (csi). Default 'psi'.\n",
    "        binning_method (str): Method for splitting variable into bins, 'quantile' or 'equal_width'. Default 'quantile'.\n",
    "         If scoring_variable is object or category column, then initial values are used, without any binning.\n",
    "        bins (int): The number of bins the population will be divided into. Default 10.\n",
    "        detail (bool): Whether to return detail info on index calculation or only index value.\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    assert index in ['psi', 'csi'], '\"index\" argument must be in [\"psi\", \"csi\"]'\n",
    "    assert binning_method in [\n",
    "        'quantile',\n",
    "        'equal_width',\n",
    "    ], '\"binning_method\" argument mustbe in [\"quantile\", \"equal_width\"]'\n",
    "    assert (scoring_variable in dev.columns) and (\n",
    "        scoring_variable in oot.columns\n",
    "    ), '\"scoring_variable\" must be in both `dev` and `out` datasets.'\n",
    "    sc_var_dev, sc_var_oot = dev[scoring_variable], oot[scoring_variable]\n",
    "    assert sc_var_dev.dtype == sc_var_oot.dtype, '\"scoring_variable\" type must be the same in both `dev` and `oot`'\n\n",
    "    # if sc_var_dev.dtype in ['object', 'category']:\n",
    "    #\n",
    "    # else:\n",
    "    #     if binning_method == 'quantile':\n",
    "    #\n",
    "    #     else:\n",
    "    if index == 'psi':\n",
    "        oot_bins = cut(sc_var_oot, bins=bins)\n",
    "        dev_bins = cut(sc_var_dev, bins=oot_bins.cat.categories)\n",
    "    else:\n",
    "        dev_bins = cut(sc_var_dev, bins=bins)\n",
    "        oot_bins = cut(sc_var_oot, bins=dev_bins.cat.categories)\n",
    "    psi = concat(\n",
    "        [\n",
    "            (oot_bins.value_counts().sort_index(ascending=False) / oot_bins.shape[0] * 100).rename('OOT'),\n",
    "            (dev_bins.value_counts().sort_index(ascending=False) / dev_bins.shape[0] * 100).rename('DEV'),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "    psi['Diff'] = psi['OOT'] - psi['DEV']\n",
    "    psi['ln_OOT_DEV'] = np.log(psi['OOT'] / psi['DEV'])\n",
    "    psi['PSI'] = psi['Diff'] * psi['ln_OOT_DEV']\n",
    "    total, total.loc[['ln_OOT_DEV', 'Diff']] = Series(np.sum(psi), name='Total'), '-'\n",
    "    psi = psi.append(total)\n",
    "    if detail:\n",
    "        return psi\n",
    "    else:\n",
    "        return total['PSI']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}