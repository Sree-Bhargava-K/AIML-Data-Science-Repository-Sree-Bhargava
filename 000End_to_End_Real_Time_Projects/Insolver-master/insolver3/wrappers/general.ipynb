{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import concatenate, array\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, SCORERS\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .base import InsolverBaseWrapper\n",
    "from .extensions import InsolverCVHPExtension, InsolverPDPExtension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsolverRFWrapper(InsolverBaseWrapper, InsolverCVHPExtension, InsolverPDPExtension):\n",
    "    \"\"\"Insolver wrapper for Random Forest.\n",
    "    Parameters:\n",
    "        backend (str): Framework for building RF, 'sklearn' is supported.\n",
    "        task (str): Task that RF should solve: Classification or Regression. Values 'reg' and 'class' are supported.\n",
    "        n_estimators (int, optional): Number of trees in the forest. Equals 100 by default.\n",
    "        load_path (str, optional): Path to RF model to load from disk.\n",
    "        **kwargs: Parameters for RF estimators except `n_estimators`. Will not be changed in hyperopt.\n",
    "    \"\"\"\n",
    "    def __init__(self, backend, task=None, n_estimators=100, load_path=None, **kwargs):\n",
    "        super(InsolverRFWrapper, self).__init__(backend)\n",
    "        self.init_args = self._get_init_args(vars())\n",
    "        self.algo, self._backends = 'rf', ['sklearn']\n",
    "        self._tasks = ['class', 'reg']\n",
    "        self._back_load_dict = {'sklearn': self._pickle_load}\n",
    "        self._back_save_dict = {'sklearn': self._pickle_save}\n",
    "        self.n_estimators, self.params = n_estimators, None\n",
    "        if backend not in self._backends:\n",
    "            raise NotImplementedError(f'Error with the backend choice. Supported backends: {self._backends}')\n",
    "        if load_path is not None:\n",
    "            self.load_model(load_path)\n",
    "        else:\n",
    "            if task in self._tasks:\n",
    "                rf_init = {'class': {'sklearn': RandomForestClassifier}, 'reg': {'sklearn': RandomForestRegressor}}\n",
    "                kwargs.update({'n_estimators': self.n_estimators})\n",
    "                self.model, self.params = rf_init[task][self.backend](**(kwargs if kwargs is not None else {})), kwargs\n",
    "                def __params_rf(**params):\n",
    "                    params.update(self.params)\n",
    "                    return rf_init[task][self.backend](**params)\n",
    "                self.object = __params_rf\n",
    "            else:\n",
    "                raise NotImplementedError(f'Task parameter supports values in {self._tasks}.')\n",
    "        self._update_meta()\n",
    "    def fit(self, X, y, report=None, **kwargs):\n",
    "        \"\"\"Fit a Random Forest.\n",
    "        Args:\n",
    "            X (pd.DataFrame, pd.Series): Training data.\n",
    "            y (pd.DataFrame, pd.Series): Training target values.\n",
    "            report (list, tuple, optional): A list of metrics to report after model fitting, optional.\n",
    "            **kwargs: Other parameters passed to Scikit-learn API .fit().\n",
    "        \"\"\"\n",
    "        self.model.fit(X, y, **kwargs)\n",
    "        if not hasattr(self.model, 'feature_name_'):\n",
    "            self.model.feature_name_ = X.columns if isinstance(X, DataFrame) else [X.name]\n",
    "        self._update_meta()\n",
    "        if report is not None:\n",
    "            if isinstance(report, (list, tuple)):\n",
    "                prediction = self.model.predict(X)\n",
    "                print(\n",
    "                    DataFrame([[x.__name__, x(y, prediction)] for x in report])\n",
    "                    .rename({0: 'Metrics', 1: 'Value'}, axis=1)\n",
    "                    .set_index('Metrics')\n",
    "                )\n",
    "    def predict(self, X, **kwargs):\n",
    "        \"\"\"Predict using RF with feature matrix X.\n",
    "        Args:\n",
    "            X (pd.DataFrame, pd.Series): Samples.\n",
    "            **kwargs: Other parameters passed to Scikit-learn API .predict().\n",
    "        Returns:\n",
    "            array: Returns predicted values.\n",
    "        \"\"\"\n",
    "        return self.model.predict(\n",
    "            X if not hasattr(self.model, 'feature_name_') else X[self.model.feature_name_], **kwargs\n",
    "        )\n",
    "    def cross_val(self, X, y, scoring=None, cv=None, **kwargs):\n",
    "        \"\"\"Method for performing cross-validation given the hyperparameters of initialized or fitted model.\n",
    "        Args:\n",
    "            X (pd.DataFrame, pd.Series): Training data.\n",
    "            y (pd.DataFrame, pd.Series): Training target values.\n",
    "            scoring (callable): Metrics passed to sklearn.model_selection.cross_validate calculation.\n",
    "            cv (int, iterable, cross-validation generator, optional): Cross-validation strategy from\n",
    "             sklearn. Performs 5-fold cv by default.\n",
    "            **kwargs: Other parameters passed to sklearn.model_selection.cross_validate.\n",
    "        Returns:\n",
    "            pd.DataFrame, pd.DataFrame: DataFrame with metrics on folds, DataFrame with shap values on folds.\n",
    "        \"\"\"\n",
    "        scoring = mean_squared_error if scoring is None else scoring\n",
    "        models, metrics = self._cross_val(X, y, scoring=scoring, cv=cv, **kwargs)\n",
    "        if callable(scoring):\n",
    "            scorers = {scoring.__name__.replace('_', ' '): array([scoring(y, self.model.predict(X))])}\n",
    "        elif isinstance(scoring, (tuple, list)):\n",
    "            scorers = {\n",
    "                scorer.__name__.replace('_', ' '): array([scorer(y, self.model.predict(X))]) for scorer in scoring\n",
    "            }\n",
    "        elif isinstance(scoring, str):\n",
    "            if scoring in SCORERS:\n",
    "                scorers = {scoring.replace('_', ' '): array([SCORERS[scoring](self.model, X=X, y=y)])}\n",
    "            else:\n",
    "                raise ValueError(f'Scorer {scoring} is not supported.')\n",
    "        else:\n",
    "            raise NotImplementedError(f'Scoring of type {scoring} is not supported')\n",
    "        metrics = DataFrame({key: concatenate((scorers[key], metrics[key])) for key in scorers.keys()}).T\n",
    "        metrics.columns = [f'Fold {i}' if i != 0 else 'Overall' for i in range(metrics.shape[1])]\n",
    "        return metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}