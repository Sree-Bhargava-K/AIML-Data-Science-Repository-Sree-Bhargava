{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from pandas import DataFrame\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import make_scorer, check_scoring, mean_squared_error\n",
    "from hyperopt import STATUS_OK, Trials, tpe, fmin, space_eval, hp\n",
    "from xgboost import XGBModel\n",
    "from catboost import CatBoost\n",
    "from lightgbm import LGBMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsolverCVHPExtension:\n",
    "    def _hyperopt_obj_cv(self, params, X, y, scoring, cv=None, agg=None, maximize=False, **kwargs):\n",
    "        \"\"\"Default hyperopt objective performing K-fold cross-validation.\n",
    "        Args:\n",
    "            params (dict): Dictionary of hyperopt parameters.\n",
    "            X (pd.DataFrame, pd.Series): Training data.\n",
    "            y (pd.DataFrame, pd.Series): Training target values.\n",
    "            scoring (callable): Metrics passed to cross_val_score calculation.\n",
    "            cv (int, iterable, cross-validation generator, optional): Cross-validation strategy from\n",
    "             sklearn. Performs 5-fold cv by default.\n",
    "            agg (callable, optional): Function computing the final score out of test cv scores.\n",
    "            maximize (bool, optional): Indicator whether to maximize or minimize objective.\n",
    "             Minimizing by default.\n",
    "            **kwargs: Other parameters passed to sklearn.model_selection.cross_val_score().\n",
    "        Returns:\n",
    "            dict: {'status': STATUS_OK, 'loss': `cv_score`}\n",
    "        \"\"\"\n",
    "        agg = mean if agg is None else agg\n",
    "        cv = KFold(n_splits=5) if cv is None else cv\n",
    "        params = {\n",
    "            key: params[key] if not (isinstance(params[key], float) and params[key].is_integer()) else int(params[key])\n",
    "            for key in params.keys()\n",
    "        }\n",
    "        njobs = -1 if 'n_jobs' not in kwargs else kwargs.pop('n_jobs')\n",
    "        error_score = 'raise' if 'error_score' not in kwargs else kwargs.pop('error_score')\n",
    "        if isinstance(self.object(), CatBoost) and 'thread_count' not in self.params.keys():\n",
    "            params.update({'thread_count': 1})\n",
    "        elif isinstance(self.object(), (XGBModel, LGBMModel)) and 'n_jobs' not in self.params.keys():\n",
    "            params.update({'n_jobs': 1})\n",
    "        estimator = self.object(**params)\n",
    "        score = agg(\n",
    "            cross_val_score(estimator, X, y=y, scoring=scoring, cv=cv, n_jobs=njobs, error_score=error_score, **kwargs)\n",
    "        )\n",
    "        score = -score if maximize else score\n",
    "        return {'status': STATUS_OK, 'loss': score}\n",
    "    def hyperopt_cv(\n",
    "        self,\n",
    "        X,\n",
    "        y,\n",
    "        params,\n",
    "        fn=None,\n",
    "        algo=None,\n",
    "        max_evals=10,\n",
    "        timeout=None,\n",
    "        fmin_params=None,\n",
    "        fn_params=None,\n",
    "        p_last=True,\n",
    "    ):\n",
    "        \"\"\"Hyperparameter optimization using hyperopt. Using cross-validation to evaluate hyperparameters by default.\n",
    "        Args:\n",
    "            X (pd.DataFrame, pd.Series): Training data.\n",
    "            y (pd.DataFrame, pd.Series): Training target values.\n",
    "            params (dict): Dictionary of hyperparameters passed to hyperopt.\n",
    "            fn (callable, optional): Objective function to optimize with hyperopt.\n",
    "            algo (callable, optional): Algorithm for hyperopt. Available choices are: hyperopt.tpe.suggest and\n",
    "             hyperopt.random.suggest. Using hyperopt.tpe.suggest by default.\n",
    "            max_evals (int, optional): Number of function evaluations before returning.\n",
    "            timeout (None, int, optional): Limits search time by parametrized number of seconds.\n",
    "             If None, then the search process has no time constraint. None by default.\n",
    "            fmin_params (dict, optional): Dictionary of supplementary arguments for hyperopt.fmin function.\n",
    "            fn_params (dict, optional):  Dictionary of supplementary arguments for custom fn objective function.\n",
    "            p_last (str, optional): If model object is a sklearn.Pipeline then apply fit parameters to the last\n",
    "             step. True by default.\n",
    "        Returns:\n",
    "            dict: Dictionary of best choice of hyperparameters. Also best model is fitted.\n",
    "        \"\"\"\n",
    "        if self.backend == 'h2o':\n",
    "            raise Exception('hyperopt_cv is not supported by `h2o` backend. Use `optimize_hyperparam`')\n",
    "        trials = Trials()\n",
    "        algo = tpe.suggest if algo is None else algo\n",
    "        if isinstance(self.model, Pipeline) and ((fn_params is not None) and ('fit_params' in fn_params)) and p_last:\n",
    "            fn_params['fit_params'] = {\n",
    "                f'{self.model.steps[-1][0]}__{key}': fn_params['fit_params'].get(key)\n",
    "                for key in fn_params['fit_params'].keys()\n",
    "            }\n",
    "        if fn is None:\n",
    "            scoring = (\n",
    "                None\n",
    "                if not (isinstance(fn_params, dict) and ('scoring' in fn_params.keys()))\n",
    "                else fn_params.pop('scoring')\n",
    "            )\n",
    "            scoring = make_scorer(mean_squared_error) if scoring is None else scoring\n",
    "            try:\n",
    "                check_scoring(self, scoring)\n",
    "            except ValueError:\n",
    "                scoring = make_scorer(scoring)\n",
    "            fn = functools.partial(\n",
    "                self._hyperopt_obj_cv, X=X, y=y, scoring=scoring, **(fn_params if fn_params is not None else {})\n",
    "            )\n",
    "        best = fmin(\n",
    "            fn=fn,\n",
    "            space=params,\n",
    "            trials=trials,\n",
    "            algo=algo,\n",
    "            max_evals=max_evals,\n",
    "            timeout=timeout,\n",
    "            **(fmin_params if fmin_params is not None else {}),\n",
    "        )\n",
    "        best_params = space_eval(params, best)\n",
    "        best_params = {\n",
    "            key: (\n",
    "                best_params[key]\n",
    "                if not (isinstance(best_params[key], float) and best_params[key].is_integer())\n",
    "                else int(best_params[key])\n",
    "            )\n",
    "            for key in best_params.keys()\n",
    "        }\n",
    "        self.best_params, self.trials = best_params, trials\n",
    "        self.model = self.object(**self.best_params)\n",
    "        self.model.fit(\n",
    "            X, y, **({} if not ((fn_params is not None) and ('fit_params' in fn_params)) else fn_params['fit_params'])\n",
    "        )\n",
    "        if not hasattr(self.model, 'feature_name_'):\n",
    "            self.model.feature_name_ = X.columns.tolist() if isinstance(X, DataFrame) else [X.name]\n",
    "        self._update_meta()\n",
    "        return self.best_params\n",
    "    def _cross_val(self, X, y, scoring=None, cv=None, **kwargs):\n",
    "        if self.backend != 'h2o':\n",
    "            cv = KFold(n_splits=5) if cv is None else cv\n",
    "            njobs = -1 if 'n_jobs' not in kwargs else kwargs.pop('n_jobs')\n",
    "            if 'return_estimator' in kwargs:\n",
    "                kwargs.pop('return_estimator')\n",
    "            scoring = make_scorer(mean_squared_error) if scoring is None else scoring\n",
    "            if callable(scoring) or isinstance(scoring, str):\n",
    "                scorers = scoring\n",
    "                try:\n",
    "                    check_scoring(self.model, scorers)\n",
    "                    scorers = {\n",
    "                        scorers.__name__.replace('_', ' '): (\n",
    "                            make_scorer(scorers)\n",
    "                            if isinstance(scorers, (types.FunctionType, types.BuiltinFunctionType, functools.partial))\n",
    "                            else scorers\n",
    "                        )\n",
    "                    }\n",
    "                except ValueError:\n",
    "                    scorers = {scorers.__name__.replace('_', ' '): make_scorer(scorers)}\n",
    "            elif isinstance(scoring, (tuple, list)):\n",
    "                scorers = []\n",
    "                for scorer in scoring:\n",
    "                    try:\n",
    "                        check_scoring(self.model, scorer)\n",
    "                        scorers.append(\n",
    "                            [\n",
    "                                scorer.__name__.replace('_', ' '),\n",
    "                                (\n",
    "                                    make_scorer(scorer)\n",
    "                                    if isinstance(\n",
    "                                        scorer, (types.FunctionType, types.BuiltinFunctionType, functools.partial)\n",
    "                                    )\n",
    "                                    else scorer\n",
    "                                ),\n",
    "                            ]\n",
    "                        )\n",
    "                    except ValueError:\n",
    "                        scorers.append([scorer.__name__.replace('_', ' '), make_scorer(scorer)])\n",
    "                scorers = {scorer[0]: scorer[1] for scorer in scorers}\n",
    "            else:\n",
    "                raise NotImplementedError(f'Scoring of type {type(scoring)} is not supported.')\n",
    "            cv_results = cross_validate(\n",
    "                self.model, X, y=y, scoring=scorers, cv=cv, n_jobs=njobs, return_estimator=True, **kwargs\n",
    "            )\n",
    "            estimators = cv_results.pop('estimator')\n",
    "            cv_results = {key.split('test_')[1]: cv_results[key] for key in cv_results if key.startswith('test_')}\n",
    "            return estimators, cv_results\n",
    "        else:\n",
    "            raise NotImplementedError('_cross_val method is not implemented for backend=`h2o`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO_SPACE_CONFIG = {\n",
    "    \"xgboost\": {\n",
    "        \"max_depth\": hp.choice('max_depth', [5, 8, 10, 12, 15]),\n",
    "        \"min_child_weight\": hp.uniform('min_child_weight', 0, 50),\n",
    "        \"subsample\": hp.uniform('subsample', 0.5, 1),\n",
    "        \"colsample_bytree\": hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        \"alpha\": hp.uniform('alpha', 0, 1),\n",
    "        \"lambda\": hp.uniform('lambda', 0, 1),\n",
    "        \"eta\": hp.uniform('eta', 0.01, 1),\n",
    "        \"gamma\": hp.uniform('gamma', 0.01, 1000),\n",
    "    },\n",
    "    \"lightgbm\": {\n",
    "        \"max_depth\": hp.choice('max_depth', [5, 8, 10, 12, 15]),\n",
    "        \"min_child_weight\": hp.uniform('min_child_weight', 0, 50),\n",
    "        \"subsample\": hp.uniform('subsample', 0.5, 1),\n",
    "        \"colsample_bytree\": hp.uniform('colsample_bytree', 0.5, 1),\n",
    "        \"alpha\": hp.uniform('alpha', 0, 1),\n",
    "        \"num_leaves\": hp.quniform('num_leaves', 31, 10000, 1),\n",
    "        \"reg_lambda\": hp.uniform('reg_lambda', 0, 1),\n",
    "        \"learning_rate\": hp.uniform('learning_rate', 0.01, 1),\n",
    "    },\n",
    "    \"catboost\": {\n",
    "        \"max_depth\": hp.choice('max_depth', [5, 8, 10, 12, 15]),\n",
    "        \"min_child_samples\": hp.uniform('min_child_samples', 0, 50),\n",
    "        \"subsample\": hp.uniform('subsample', 0.5, 1),\n",
    "        \"colsample_bylevel\": hp.uniform('colsample_bylevel', 0.5, 1),\n",
    "        \"reg_lambda\": hp.uniform('reg_lambda', 2, 30),\n",
    "        \"learning_rate\": hp.uniform('learning_rate', 0.01, 1),\n",
    "    },\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}