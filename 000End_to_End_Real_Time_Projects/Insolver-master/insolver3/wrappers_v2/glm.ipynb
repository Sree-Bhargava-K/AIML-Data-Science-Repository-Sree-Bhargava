{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.version_info >= (3, 8):\n",
    "    from typing import Literal\n",
    "else:\n",
    "    from typing_extensions import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import PathLike\n",
    "from typing import Optional, Dict, Any, Union, List, Tuple, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import PoissonRegressor, GammaRegressor, TweedieRegressor, LogisticRegression, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.frame import H2OFrame\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import repeat, ndarray, insert, sum as npsum, sqrt, exp, true_divide, hstack, ones\n",
    "from pandas import DataFrame, Series, concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ..utils import warn_insolver\n",
    "from .base import InsolverBaseWrapper, InsolverWrapperWarning\n",
    "from .utils import save_pickle, save_dill, save_h2o\n",
    "from .utils.h2o_utils import x_y_to_h2o_frame, h2o_start, h2o_stop, to_h2oframe, load_h2o\n",
    "from .utils.hypertoptcv import hyperopt_cv_proc, tpe, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsolverGLMWrapper(InsolverBaseWrapper):\n",
    "    \"\"\"Insolver wrapper for Generalized Linear Models.\n",
    "    Parameters:\n",
    "        backend (str): Framework for building GLM, currently 'h2o' and 'sklearn' are supported.\n",
    "        task (str): Task that GLM should solve: Classification or Regression. Values 'reg' and 'class' are supported.\n",
    "        family (str, float, int, optional): Distribution for GLM. Supports any family from h2o as\n",
    "          str. For sklearn supported `str` families are ['gaussian', 'normal', 'poisson', 'gamma', 'inverse_gaussian'],\n",
    "          also may be defined as `int` or `float` as a power for Tweedie GLM. By default, Gaussian GLM is fitted.\n",
    "        link (str, optional): Link function for GLM. If `None`, sets to default value for both h2o and sklearn.\n",
    "        h2o_init_params (dict, optional): Parameters passed to `h2o.init()`, when `backend` == 'h2o'.\n",
    "        **kwargs: Parameters for GLM estimators (for H2OGeneralizedLinearEstimator or TweedieRegressor) except\n",
    "          `family` (`power` for TweedieRegressor) and `link`.\n",
    "    \"\"\"\n",
    "    algo = 'glm'\n",
    "    _backends = [\"h2o\", \"sklearn\"]\n",
    "    _tasks = [\"class\", \"reg\"]\n",
    "    _backend_saving_methods = {'sklearn': {'pickle': save_pickle, 'dill': save_dill}, 'h2o': {'h2o': save_h2o}}\n",
    "    def __init__(\n",
    "        self,\n",
    "        backend: Optional[Literal['sklearn', 'h2o']],\n",
    "        task: Literal['class', 'reg'] = 'reg',\n",
    "        family: Optional[str] = None,\n",
    "        link: Optional[str] = None,\n",
    "        h2o_server_params: Optional[Dict] = None,\n",
    "        **kwargs: Any,\n",
    "    ):\n",
    "        self._get_init_args(vars())\n\n",
    "        # Checks on supported backends and tasks\n",
    "        if backend not in self._backends:\n",
    "            raise ValueError(f'Invalid \"{backend}\" backend argument. Supported backends: {self._backends}.')\n",
    "        if task not in self._tasks:\n",
    "            raise ValueError(f'Invalid \"{task}\" task argument. Supported tasks: {self._tasks}.')\n",
    "        self.backend = backend\n",
    "        self.task = task\n",
    "        self.family = family\n",
    "        self.link = link\n",
    "        self.h2o_server_params = h2o_server_params\n",
    "        self.kwargs = kwargs\n",
    "        self.best_params: Optional[Dict[str, Any]] = None\n",
    "        self.trials = None\n",
    "        self.model = self.init_model()\n",
    "        self.__dict__.update(self.metadata)\n",
    "    def _init_glm_sklearn(self, **params: Any) -> BaseEstimator:\n",
    "        model = BaseEstimator()  # Just to mitigate referenced before assignment warning\n\n",
    "        # Checks on supported families vs tasks\n",
    "        if self.family not in [None, 'poisson', 'gamma', 'tweedie', 'normal', 'gaussian', 'inverse_gaussian', 'logit']:\n",
    "            raise ValueError(f'Distribution family \"{self.family}\" is not supported with sklearn backend.')\n",
    "        else:\n",
    "            if (self.family in ['logit']) and (self.task == 'reg'):\n",
    "                raise ValueError(f'Distribution family \"{self.family}\" does not match the task \"{self.task}\".')\n",
    "            if (self.family not in [None, 'logit']) and (self.task == 'class'):\n",
    "                raise ValueError(f'Distribution family \"{self.family}\" does not match the task \"{self.task}\".')\n",
    "            if self.family is None:\n",
    "                self.family = 'gaussian' if self.task == 'reg' else 'logit'\n\n",
    "        # Checks on supported families vs links\n",
    "        if self.family in ['gamma', 'poisson']:\n",
    "            self.link = 'log' if self.link is None else self.link\n",
    "            if self.link != 'log':\n",
    "                warn_insolver(\n",
    "                    f'Link function \"{self.link}\" not supported for \"{self.family}\",using default \"log\" link',\n",
    "                    InsolverWrapperWarning,\n",
    "                )\n",
    "        if self.family in ['tweedie', 'inverse_gaussian']:\n",
    "            self.link = 'log' if self.link is None else self.link\n",
    "            if self.link not in ['log', 'identity']:\n",
    "                warn_insolver(\n",
    "                    f'Link function \"{self.link}\" not supported for \"{self.family}\",using default \"log\" link',\n",
    "                    InsolverWrapperWarning,\n",
    "                )\n",
    "        if self.family in ['normal', 'gaussian']:\n",
    "            self.link = 'identity' if self.link is None else self.link\n",
    "            if self.link != 'identity':\n",
    "                warn_insolver(\n",
    "                    f'Link function \"{self.link}\" not supported for \"{self.family}\",using default \"identity\" link',\n",
    "                    InsolverWrapperWarning,\n",
    "                )\n",
    "        if self.family in ['normal', 'gaussian']:\n",
    "            self.link = 'identity' if self.link is None else self.link\n",
    "            if self.link != 'identity':\n",
    "                warn_insolver(\n",
    "                    f'Link function \"{self.link}\" not supported for \"{self.family}\",using default \"identity\" link',\n",
    "                    InsolverWrapperWarning,\n",
    "                )\n",
    "        if self.family == 'logit':\n",
    "            self.link = 'logit' if self.link is None else self.link\n",
    "            if self.link != 'logit':\n",
    "                warn_insolver(\n",
    "                    f'Link function \"{self.link}\" not supported for \"{self.family}\",using default \"logit\" link',\n",
    "                    InsolverWrapperWarning,\n",
    "                )\n\n",
    "        # Estimator initialization\n",
    "        if self.family == 'poisson':\n",
    "            # alpha=1.0, fit_intercept=True, max_iter=100, tol=0.0001, warm_start=False, verbose=0\n",
    "            model = PoissonRegressor(**params)\n",
    "        if self.family == 'gamma':\n",
    "            # alpha=1.0, fit_intercept=True, max_iter=100, tol=0.0001, warm_start=False, verbose=0\n",
    "            model = GammaRegressor(**params)\n",
    "        if self.family == 'tweedie':\n",
    "            # power=0.0, alpha=1.0, fit_intercept=True, link='auto', max_iter=100, tol=0.0001,\n",
    "            # warm_start=False, verbose=0\n",
    "            model = TweedieRegressor(**params)\n",
    "        if self.family == 'inverse_gaussian':\n",
    "            # alpha=1.0, fit_intercept=True, max_iter=100, tol=0.0001, warm_start=False, verbose=0\n",
    "            model = TweedieRegressor(power=3, **params)\n",
    "        if self.family in ['normal', 'gaussian']:\n",
    "            # alpha=1.0, l1_ratio=0.5, fit_intercept=True, normalize='deprecated', precompute=False,\n",
    "            # max_iter=1000, copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None,\n",
    "            # selection='cyclic'\n",
    "            model = ElasticNet(**params)\n",
    "        if self.family == 'logit':\n",
    "            # penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None,\n",
    "            # random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False,\n",
    "            # n_jobs=None, l1_ratio=None\n",
    "            model = LogisticRegression(**params)\n",
    "        if self.family in ['poisson', 'gamma', 'tweedie', 'inverse_gaussian']:\n",
    "            # Since sklearn GLM tend to fail optimization on non-standardized data\n",
    "            model = Pipeline([('scaler', StandardScaler(with_mean=True, with_std=True)), ('glm', model)])\n",
    "            self.metadata.update({'is_standardized': True})\n",
    "        else:\n",
    "            self.metadata.update({'is_standardized': False})\n",
    "        return model\n",
    "    def _init_glm_h2o(self, **params: Any) -> H2OGeneralizedLinearEstimator:\n",
    "        model = H2OGeneralizedLinearEstimator(family=self.family, link=self.link, **params)\n",
    "        return model\n",
    "    def init_model(self, additional_params: Optional[Dict] = None) -> Any:\n",
    "        model = None\n",
    "        params = self.metadata['init_params']['kwargs']\n",
    "        if additional_params is not None:\n",
    "            params.update(additional_params)\n",
    "        if self.backend == 'sklearn':\n",
    "            model = self._init_glm_sklearn(**params)\n",
    "        if self.backend == 'h2o':\n",
    "            model = self._init_glm_h2o(**params)\n",
    "        self._update_metadata()\n",
    "        return model\n",
    "    def fit(\n",
    "        self,\n",
    "        x: Union[DataFrame, Series],\n",
    "        y: Union[DataFrame, Series],\n",
    "        sample_weight: Union[None, DataFrame, Series] = None,\n",
    "        x_valid: Union[None, DataFrame, Series] = None,\n",
    "        y_valid: Union[None, DataFrame, Series] = None,\n",
    "        sample_weight_valid: Union[None, DataFrame, Series] = None,\n",
    "        report: Union[None, List, Tuple, Callable] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Fit a Generalized Linear Model.\n",
    "        Args:\n",
    "            x (pd.DataFrame, pd.Series): Training data.\n",
    "            y (pd.DataFrame, pd.Series): Training target values.\n",
    "            sample_weight (pd.DataFrame, pd.Series, optional): Training sample weights.\n",
    "            x_valid (pd.DataFrame, pd.Series, optional): Validation data (only h2o supported).\n",
    "            y_valid (pd.DataFrame, pd.Series, optional): Validation target values (only h2o supported).\n",
    "            sample_weight_valid (pd.DataFrame, pd.Series, optional): Validation sample weights.\n",
    "            report (list, tuple, optional): A list of metrics to report after model fitting, optional.\n",
    "            **kwargs: Other parameters passed to H2OGeneralizedLinearEstimator.\n",
    "        \"\"\"\n",
    "        for arg in [x, y, sample_weight, x_valid, y_valid, sample_weight_valid]:\n",
    "            if (arg is not None) and (not isinstance(arg, (DataFrame, Series))):\n",
    "                argname = [k for k, v in locals().items() if v == arg][0]\n",
    "                raise TypeError(\n",
    "                    f'Invalid type {type(arg)} for \"{argname}\". It must be either pd.DataFrame or pd.Series.'\n",
    "                )\n",
    "        for y_var in [y, y_valid]:\n",
    "            if isinstance(y_var, DataFrame) and y_var.shape[1] > 1:\n",
    "                argname = [k for k, v in locals().items() if v == y_var][0]\n",
    "                raise ValueError(f'Argument \"{argname}\" must be a one-dimensional DataFrame.')\n",
    "        features = list(x.columns) if isinstance(x, DataFrame) else [x.name]\n",
    "        target = list(y.columns) if isinstance(y, DataFrame) else y.name\n",
    "        self.metadata.update({'feature_names': features, 'target': target})\n",
    "        prediction = None\n",
    "        if self.backend == 'sklearn':\n",
    "            if any(arg is not None for arg in [x_valid, y_valid, sample_weight_valid]):\n",
    "                warn_insolver(\n",
    "                    'Arguments x_valid, y_valid, sample_weight_valid are not supported by sklearn backend',\n",
    "                    InsolverWrapperWarning,\n",
    "                )\n",
    "            if self.metadata['is_standardized']:\n",
    "                self.model.fit(x, y, glm__sample_weight=sample_weight)\n",
    "            else:\n",
    "                self.model.fit(x, y, sample_weight=sample_weight)\n",
    "            self.metadata.update({'is_fitted': True})\n",
    "            self.metadata.update({'coefs': self.coef()})\n",
    "            if isinstance(report, (list, tuple)) or callable(report):\n",
    "                prediction = self.model.predict(x)\n",
    "        if self.backend == 'h2o':\n",
    "            h2o_start()\n",
    "            train_set, params = x_y_to_h2o_frame(x, y, sample_weight, {**kwargs}, x_valid, y_valid, sample_weight_valid)\n",
    "            self.model.train(y=target, x=features, training_frame=train_set, **params)\n",
    "            self.metadata.update({'is_fitted': True})\n",
    "            self.metadata.update({'coefs': self.coef()})\n",
    "            if isinstance(report, (list, tuple)) or callable(report):\n",
    "                prediction = self.model.predict(train_set).as_data_frame().values.reshape(-1)\n",
    "            self._model_cached = self.save_model()\n",
    "            h2o_stop()\n",
    "        if prediction is not None:\n",
    "            if not callable(report) and (report is not None):\n",
    "                print(\n",
    "                    DataFrame([[x.__name__, x(y, prediction)] for x in report], columns=['Metrics', 'Value']).set_index(\n",
    "                        'Metrics'\n",
    "                    )\n",
    "                )\n",
    "            if callable(report) and (report is not None):\n",
    "                print(\n",
    "                    DataFrame([[report.__name__, report(y, prediction)]], columns=['Metrics', 'Value']).set_index(\n",
    "                        'Metrics'\n",
    "                    )\n",
    "                )\n",
    "    def predict(\n",
    "        self, x: Union[DataFrame, Series], sample_weight: Union[None, DataFrame, Series] = None, **kwargs: Any\n",
    "    ) -> Optional[ndarray]:\n",
    "        \"\"\"Predict using GLM with feature matrix X.\n",
    "        Args:\n",
    "            x (pd.DataFrame, pd.Series): Samples.\n",
    "            sample_weight (pd.DataFrame, pd.Series, optional): Test sample weights.\n",
    "            **kwargs: Other parameters passed to H2OGeneralizedLinearEstimator.predict().\n",
    "        Returns:\n",
    "            array: Returns predicted values.\n",
    "        \"\"\"\n",
    "        if not self.metadata['is_fitted']:\n",
    "            raise ValueError(\"This instance is not fitted yet. Call '.fit(...)' before using this estimator.\")\n",
    "        if not isinstance(x, (DataFrame, Series)):\n",
    "            raise TypeError(f'Invalid type {type(x)} for \"x\". It must be either pd.DataFrame or pd.Series.')\n",
    "        predictions = None\n",
    "        if self.backend == 'sklearn':\n",
    "            predictions = self.model.predict(x[self.metadata['feature_names']] if isinstance(x, DataFrame) else x)\n",
    "        if self.backend == 'h2o':\n",
    "            if self._model_cached is not None:\n",
    "                load_h2o(self._model_cached, self.h2o_server_params, terminate=False)\n",
    "            if self.model.parms['offset_column']['actual_value'] is not None and sample_weight is None:\n",
    "                offset_name = self.model.parms['offset_column']['actual_value']['column_name']\n",
    "                sample_weight = Series(repeat(1, len(x)), name=offset_name, index=x.index)\n",
    "            if sample_weight is not None:\n",
    "                x = concat([x, sample_weight], axis=1)\n",
    "            h2o_predict = x if isinstance(x, H2OFrame) else to_h2oframe(x)\n",
    "            predictions = self.model.predict(h2o_predict, **kwargs).as_data_frame().values.reshape(-1)\n",
    "            h2o_stop()\n",
    "        return predictions\n",
    "    def predict_coef(self, x: Union[DataFrame, Series]) -> Optional[ndarray]:\n",
    "        \"\"\"Predict using only GLM coefficients (without model itself) with feature matrix X.\n",
    "        Args:\n",
    "            x (pd.DataFrame, pd.Series): Samples.\n",
    "        Returns:\n",
    "            array: Returns predicted values.\n",
    "        \"\"\"\n",
    "        if (not self.metadata['is_fitted']) or ('coefs' not in self.metadata.keys()):\n",
    "            raise ValueError(\"This instance is not fitted yet. Call '.fit(...)' before using this estimator.\")\n",
    "        if not isinstance(x, (DataFrame, Series)):\n",
    "            raise TypeError(f'Invalid type {type(x)} for \"x\". It must be either pd.DataFrame or pd.Series.')\n",
    "        def link_identity(lin_pred: ndarray) -> ndarray:\n",
    "            return lin_pred\n",
    "        def link_log(lin_pred: ndarray) -> ndarray:\n",
    "            return exp(lin_pred)\n",
    "        def link_inverse(lin_pred: ndarray) -> ndarray:\n",
    "            return true_divide(1, lin_pred)\n",
    "        def link_logit(lin_pred: ndarray) -> ndarray:\n",
    "            return true_divide(exp(-lin_pred), 1 + exp(-lin_pred))\n\n",
    "        # def link_ologit(lin_pred):\n",
    "        #     pass\n",
    "        #\n",
    "        # def link_tweedie(lin_pred):\n",
    "        #     pass\n",
    "        link_map = {'identity': link_identity, 'log': link_log, 'inverse': link_inverse, 'logit': link_logit}\n",
    "        coefs = self.metadata['coefs']\n",
    "        if isinstance(x, DataFrame):\n",
    "            difference = set(coefs).difference(set(x.columns))\n",
    "        elif isinstance(x, Series):\n",
    "            difference = set(coefs).difference({x.name})\n",
    "        else:\n",
    "            difference = {'Intercept'}\n",
    "        difference.discard('Intercept')\n",
    "        if difference != set():\n",
    "            raise KeyError(f'Input data missing columns: {difference}')\n",
    "        coefs = Series(coefs)\n",
    "        x_ = x[coefs.index.drop('Intercept')] if isinstance(x, DataFrame) else x\n",
    "        x_ = hstack((ones((x_.shape[0], 1)), x_.values))\n",
    "        linear_prediction = x_.dot(coefs.values)\n",
    "        if self.metadata['link'] in ['ologit', 'tweedie']:\n",
    "            raise NotImplementedError(f\"Link function `{self.metadata['link']}` is not implemented.\")\n",
    "        else:\n",
    "            return link_map[self.metadata['link']](linear_prediction).reshape(-1)\n",
    "    def coef_norm(self) -> Optional[Dict[str, float]]:\n",
    "        \"\"\"Output GLM coefficients for standardized data.\n",
    "        Returns:\n",
    "            dict: {`str`: `float`} Dictionary containing GLM coefficients for standardized data.\n",
    "        \"\"\"\n",
    "        if not self.metadata['is_fitted']:\n",
    "            raise ValueError(\"This instance is not fitted yet. Call '.fit(...)' before using this estimator.\")\n",
    "        coefs = None\n",
    "        if self.backend == 'sklearn':\n",
    "            if self.metadata['is_standardized']:\n",
    "                if self.metadata['feature_names'] is None:\n",
    "                    features_ = [f'Feature_{i}' for i in range(len(self.model.named_steps['glm'].coef_))]\n",
    "                    self.metadata['feature_names'] = features_\n",
    "                else:\n",
    "                    features_ = self.metadata['feature_names']\n",
    "                _zip = zip(\n",
    "                    ['Intercept'] + features_,\n",
    "                    insert(self.model.named_steps['glm'].coef_, 0, self.model.named_steps['glm'].intercept_),\n",
    "                )\n",
    "                coefs = {x: y for x, y in _zip}\n",
    "            else:\n",
    "                raise NotImplementedError(f'Current method does not support {self.family} family.')\n",
    "        if self.backend == 'h2o':\n",
    "            coefs = self.model.coef_norm()\n",
    "        return coefs\n",
    "    def coef(self) -> Optional[Dict[str, float]]:\n",
    "        \"\"\"Output GLM coefficients for non-standardized data. Also calculated when GLM fitted on standardized data.\n",
    "        Returns:\n",
    "            dict: {`str`: `float`} Dictionary containing GLM coefficients for non-standardized data.\n",
    "        \"\"\"\n",
    "        if not self.metadata['is_fitted']:\n",
    "            raise ValueError(\"This instance is not fitted yet. Call '.fit(...)' before using this estimator.\")\n",
    "        coefs = None\n",
    "        if self.backend == 'sklearn':\n",
    "            if self.metadata['feature_names'] is None:\n",
    "                if self.metadata['is_standardized']:\n",
    "                    features_ = [f'Feature_{i}' for i in range(len(self.model.named_steps['glm'].coef_))]\n",
    "                else:\n",
    "                    features_ = [f'Feature_{i}' for i in range(len(self.model.coef_))]\n",
    "                self.metadata['feature_names'] = features_\n",
    "            else:\n",
    "                features_ = self.metadata['feature_names']\n",
    "            if self.metadata['is_standardized']:\n",
    "                _int = self.model.named_steps['glm'].intercept_\n",
    "                _coef = self.model.named_steps['glm'].coef_\n",
    "                _mean = self.model.named_steps['scaler'].mean_\n",
    "                _var = self.model.named_steps['scaler'].var_\n",
    "                intercept = _int - npsum(_coef * _mean / sqrt(_var))\n",
    "                coefs_ = _coef / sqrt(_var)\n",
    "            else:\n",
    "                intercept = self.model.intercept_\n",
    "                coefs_ = self.model.coef_\n",
    "            _zip = zip(['Intercept'] + features_, insert(coefs_, 0, intercept))\n",
    "            coefs = {x: y for x, y in _zip}\n",
    "        if self.backend == 'h2o':\n",
    "            coefs = self.model.coef()\n",
    "        return coefs\n",
    "    def coef_to_csv(self, path_or_buf: Union[None, str, 'PathLike[str]'] = None, **kwargs: Any) -> None:\n",
    "        \"\"\"Write GLM coefficients to a comma-separated values (csv) file.\n",
    "        Args:\n",
    "            path_or_buf : str or file handle, default None\n",
    "                File path or object, if None is provided the result is returned as\n",
    "                a string.  If a non-binary file object is passed, it should be opened\n",
    "                with `newline=''`, disabling universal newlines. If a binary\n",
    "                file object is passed, `mode` might need to contain a `'b'`.\n",
    "            **kwargs: Other parameters passed to Pandas DataFrame.to_csv method.\n",
    "        Returns:\n",
    "            None or str\n",
    "                If path_or_buf is None, returns the resulting csv format as a\n",
    "                string. Otherwise, returns None.\n",
    "        \"\"\"\n",
    "        result = DataFrame()\n",
    "        sources_methods = {\n",
    "            'coefficients for standardized data': self.coef_norm,\n",
    "            'coefficients for non-standardized data': self.coef,\n",
    "        }\n",
    "        for name, method in sources_methods.items():\n",
    "            try:\n",
    "                column = method()\n",
    "                if isinstance(column, dict):\n",
    "                    result = result.join(Series(column, name=name), how='outer')\n",
    "            except NotImplementedError:\n",
    "                pass\n",
    "        if result.size > 0:\n",
    "            if path_or_buf is None:\n",
    "                return result.to_csv(path_or_buf, **kwargs)\n",
    "            else:\n",
    "                result.to_csv(path_or_buf, **kwargs)\n",
    "        else:\n",
    "            warn_insolver('No coefficients available!', InsolverWrapperWarning)\n",
    "    def hyperopt_cv(\n",
    "        self,\n",
    "        x: Union[DataFrame, Series],\n",
    "        y: Union[DataFrame, Series],\n",
    "        params: Dict[str, Any],\n",
    "        fn: Callable = None,\n",
    "        algo: Union[None, rand.suggest, tpe.suggest] = None,\n",
    "        max_evals: int = 10,\n",
    "        timeout: Optional[int] = None,\n",
    "        fmin_params: Dict[str, Any] = None,\n",
    "        fn_params: Dict[str, Any] = None,\n",
    "    ) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"Hyperparameter optimization using hyperopt. Using cross-validation to evaluate hyperparameters by default.\n",
    "        Args:\n",
    "            x (pd.DataFrame, pd.Series): Training data.\n",
    "            y (pd.DataFrame, pd.Series): Training target values.\n",
    "            params (dict): Dictionary of hyperparameters passed to hyperopt.\n",
    "            fn (callable, optional): Objective function to optimize with hyperopt.\n",
    "            algo (callable, optional): Algorithm for hyperopt. Available choices are: hyperopt.tpe.suggest and\n",
    "             hyperopt.random.suggest. Using hyperopt.tpe.suggest by default.\n",
    "            max_evals (int, optional): Number of function evaluations before returning.\n",
    "            timeout (None, int, optional): Limits search time by parametrized number of seconds.\n",
    "             If None, then the search process has no time constraint. None by default.\n",
    "            fmin_params (dict, optional): Dictionary of supplementary arguments for hyperopt.fmin function.\n",
    "            fn_params (dict, optional):  Dictionary of supplementary arguments for custom fn objective function.\n",
    "        Returns:\n",
    "            dict: Dictionary of the best choice of hyperparameters. Also, best model is fitted.\n",
    "        \"\"\"\n",
    "        if self.backend == 'h2o':\n",
    "            raise NotImplementedError(\"Method hyperopt_cv() is not supported for backend == 'h2o'\")\n\n",
    "        # If model is a Pipeline, then tune parameters for its last step.\n",
    "        if isinstance(self.model, Pipeline) and ((fn_params is not None) and (\"fit_params\" in fn_params)):\n",
    "            fn_params[\"fit_params\"] = {\n",
    "                f\"{self.model.steps[-1][0]}__{key}\": fn_params[\"fit_params\"].get(key)\n",
    "                for key in fn_params[\"fit_params\"].keys()\n",
    "            }\n",
    "        self.best_params, self.trials = hyperopt_cv_proc(\n",
    "            self, x, y, params, fn, algo, max_evals, timeout, fmin_params, fn_params\n",
    "        )\n",
    "        self._update_metadata()\n",
    "        self.model = self.init_model(self.best_params)\n",
    "        self.fit(\n",
    "            x, y, **({} if not ((fn_params is not None) and (\"fit_params\" in fn_params)) else fn_params[\"fit_params\"])\n",
    "        )\n",
    "        return self.best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}