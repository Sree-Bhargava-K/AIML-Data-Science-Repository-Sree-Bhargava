{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from insolver.model_tools import ModelMetricsCompare\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from .error_handler import error_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@error_handler(False)\n",
    "def _create_models_comparison(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_test,\n",
    "    y_test,\n",
    "    dataset,\n",
    "    task,\n",
    "    models_to_compare,\n",
    "    comparison_metrics,\n",
    "    f_groups_type,\n",
    "    f_bins,\n",
    "    f_start,\n",
    "    f_end,\n",
    "    f_freq,\n",
    "    p_groups_type,\n",
    "    p_bins,\n",
    "    p_start,\n",
    "    p_end,\n",
    "    p_freq,\n",
    "    d_groups_type,\n",
    "    d_bins,\n",
    "    d_start,\n",
    "    d_end,\n",
    "    d_freq,\n",
    "    model,\n",
    "    main_diff_model,\n",
    "    compare_diff_models,\n",
    "    m_bins,\n",
    "    m_freq,\n",
    "    pairs_for_matrix,\n",
    "    **kwargs,\n",
    "):\n",
    "    articles = []\n",
    "    icons = {'train': '<i class=\"bi bi-clipboard\"></i>', 'test': '<i class=\"bi bi-clipboard-check\"></i>'}\n",
    "    for key, value in {'train': [x_train, y_train], 'test': [x_test, y_test]}.items():\n",
    "        # footer values are used by js in the report_template\n",
    "        footer = {}\n",
    "        # compare using ModelMetricsCompare and footer values\n",
    "        footer[f'metrics_chart_{key}'], metrics = _get_ModelMetricsCompare(\n",
    "            value[0], value[1], task, models_to_compare, comparison_metrics\n",
    "        )\n",
    "        # get features comparison and footer values\n",
    "        footer[f'features_{key}'], feat_html_grid = _create_features_comparison(\n",
    "            key, value[0], value[1], dataset, models_to_compare, f_groups_type, f_bins, f_start, f_end, f_freq\n",
    "        )\n",
    "        # get predict groups and footer values\n",
    "        footer[f'predict_gp_{key}'], pr_gr_grid = _create_predict_groups(\n",
    "            key, value[0], value[1], models_to_compare, p_groups_type, p_bins, p_start, p_end, p_freq\n",
    "        )\n",
    "        # get difference comparison and footer values\n",
    "        footer[f'diff_{key}'], diff_grid = _create_difference_comparison(\n",
    "            key,\n",
    "            value[0],\n",
    "            value[1],\n",
    "            model,\n",
    "            models_to_compare,\n",
    "            main_diff_model,\n",
    "            compare_diff_models,\n",
    "            d_groups_type,\n",
    "            d_bins,\n",
    "            d_start,\n",
    "            d_end,\n",
    "            d_freq,\n",
    "        )\n",
    "        articles.append(\n",
    "            {\n",
    "                'name': f'Compare on {key} data',\n",
    "                'parts': [\n",
    "                    '<div class=\"p-3 m-3 bg-light border rounded-3 fw-light\">'\n",
    "                    '<h4 class=\"text-center fw-light\">Metrics comparison chart:</h4>'\n",
    "                    f'<canvas id=\"comparison_{key}\"></canvas>'\n",
    "                    '</div>'\n",
    "                    '<div class=\"p-3 m-3 bg-light border rounded-3 text-center fw-light\">'\n",
    "                    '<h4 class=\"text-center fw-light\">Metrics comparison table:</h4>'\n",
    "                    f'{metrics.to_html(**kwargs)}'\n",
    "                    '</div>'\n",
    "                    '<div class=\"p-3 m-3 bg-light border rounded-3 text-center fw-light\">'\n",
    "                    '<h4 class=\"text-center fw-light\">Predict groups chart:</h4>'\n",
    "                    f'{pr_gr_grid}'\n",
    "                    '</div>'\n",
    "                    '<div class=\"p-3 m-3 bg-light border rounded-3 text-center fw-light\">'\n",
    "                    '<h4 class=\"text-center fw-light\">Difference chart:</h4>'\n",
    "                    f'{diff_grid}'\n",
    "                    '</div>'\n",
    "                    '<div class=\"p-3 m-3 bg-light border rounded-3 text-center fw-light\">'\n",
    "                    '<h4 class=\"text-center fw-light\">Features comparison chart:</h4>'\n",
    "                    f'{feat_html_grid}'\n",
    "                    '</div>'\n",
    "                    '<div class=\"p-3 m-3 bg-light border rounded-3 text-center fw-light\">'\n",
    "                    '<h4 class=\"text-center fw-light\">Comparison matrix:</h4>'\n",
    "                    f'{_create_comparison_matrix(value[0], value[1], pairs_for_matrix, m_bins, m_freq)}'\n",
    "                    '</div>'\n",
    "                ],\n",
    "                'header': '',\n",
    "                'footer': footer,\n",
    "                'icon': icons[key],\n",
    "            }\n",
    "        )\n",
    "    return {\n",
    "        'name': 'Compare models',\n",
    "        'articles': articles,\n",
    "        'icon': '<i class=\"bi bi-binoculars\"></i>',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ModelMetricsCompare(x, y, task, source, comparison_metrics):\n",
    "    # use ModelMetricsCompare to create comparison dataframes\n",
    "    mc = ModelMetricsCompare(x, y, task, source=source, metrics=comparison_metrics)\n",
    "    mc.compare()\n",
    "    metrics = mc.metrics_results\n",
    "    metrics_columns = metrics.columns[2:]\n",
    "    result = {'chart_name': 'Metrics comparison', 'models': list(metrics['Algo']), 'labels': list(metrics_columns)}\n",
    "    for i in range(len(metrics)):\n",
    "        row = metrics.iloc[i - 1]\n",
    "        result[row['Algo']] = list(row[metrics_columns])\n",
    "    return result, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_features_comparison(data_type, x, y, dataset, models_to_compare, groups_type, bins, start, end, freq):\n",
    "    features = x.columns\n",
    "    nav_items = ''\n",
    "    tab_pane_items = ''\n",
    "    result = {\n",
    "        'features_names': list(features),\n",
    "    }\n",
    "    for feature in features:\n",
    "        # get x values from dataset using x_test and x_train indexes\n",
    "        _x = dataset.loc[x.index].drop([y.name], axis=1)\n",
    "        x_y = pd.concat([_x, y], axis=1)\n",
    "        models = []\n",
    "        # create predict columns\n",
    "        for model in models_to_compare:\n",
    "            y_pred = model.predict(x)\n",
    "            try:\n",
    "                model_name = model.algo\n",
    "            except AttributeError:\n",
    "                model_name = model.__class__.__name__\n",
    "            model_name = f'{model_name}_1' if model_name in x_y.columns else model_name\n",
    "            x_y[model_name] = y_pred\n",
    "            models.append(model_name)\n",
    "        result['models'] = list(models)\n",
    "        result['models'].append('target')\n",
    "        x_y['group'] = _cut_column(x_y[feature], groups_type, bins, start, end, freq)\n\n",
    "        # save the grouped feature and the count\n",
    "        feature_groups_count = x_y[[feature, 'group']].groupby('group', as_index=False).count()\n",
    "        result[f'{feature}_bins'] = list(feature_groups_count['group'].astype(str))\n",
    "        result[f'{feature}_count'] = list(feature_groups_count[feature])\n\n",
    "        # count models mean values in groups\n",
    "        models_columns = list(models)\n",
    "        models_columns.append('group')\n",
    "        models_columns.append(y.name)\n",
    "        feature_groups_mean = x_y[models_columns].groupby('group', as_index=False).mean()\n\n",
    "        # save to result\n",
    "        result[feature] = {'target': list(round(feature_groups_mean[y.name].fillna(0), 3))}\n",
    "        for name in models:\n",
    "            result[feature][name] = list(round(feature_groups_mean[name].fillna(0), 3))\n",
    "        nav_class = \"nav-link active\" if feature == features[0] else \"nav-link\"\n",
    "        # replace ' ' so that href could work correctly\n",
    "        feature_replaced = feature.replace(' ', '_')\n",
    "        nav_items += f'''\n",
    "        <li class=\"nav-item\">\n",
    "            <a class=\"{nav_class}\" aria-current=\"true\" href=\"#comparison_{feature_replaced}_{data_type}\"\n",
    "            data-bs-toggle=\"tab\">\n",
    "            {feature}</a>\n",
    "        </li>'''\n",
    "        tab_pane_class = \"tab-pane active\" if feature == features[0] else \"tab-pane\"\n",
    "        tab_pane_items += f'''\n",
    "        <div class=\"{tab_pane_class}\" id=\"comparison_{feature_replaced}_{data_type}\">\n",
    "            <div id=\"features_comparison_{feature}_{data_type}\"></div>\n",
    "        </div>\n",
    "        '''\n",
    "    return (\n",
    "        result,\n",
    "        f'''\n",
    "    <div class=\"card text-center\">\n",
    "        <div class=\"card-header\">\n",
    "            <ul class=\"nav nav-tabs card-header-tabs text-nowrap p-3\" data-bs-tabs=\"tabs\"\n",
    "            style=\"overflow-x: auto;\">\n",
    "                {nav_items}\n",
    "            </ul>\n",
    "        </div>\n",
    "        <form class=\"card-body tab-content\">\n",
    "            {tab_pane_items}\n",
    "        </form>\n",
    "    </div>''',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_predict_groups(data_type, x, y, models_to_compare, groups_type, bins, start, end, freq):\n",
    "    nav_items = ''\n",
    "    tab_pane_items = ''\n",
    "    y_list = list(y)\n",
    "    # save diag values as [y_list, y_list]\n",
    "    result = {\n",
    "        'diag': [y_list, y_list],\n",
    "    }\n",
    "    models = []\n",
    "    for model in models_to_compare:\n",
    "        try:\n",
    "            model_name = model.algo\n",
    "        except AttributeError:\n",
    "            model_name = model.__class__.__name__\n",
    "        y_pred = model.predict(x)\n",
    "        # create Dataframe to save and group values\n",
    "        df_y = pd.DataFrame(y.copy())\n",
    "        model_name = f'{model_name}_1' if model_name in models else model_name\n",
    "        df_y[model_name] = y_pred\n",
    "        models.append(model_name)\n",
    "        df_y['group'] = _cut_column(df_y[model_name], groups_type, bins, start, end, freq)\n\n",
    "        # count predict results in groups\n",
    "        model_groups_count = df_y[[model_name, 'group']].groupby('group', as_index=False).count()\n",
    "        model_groups_count = model_groups_count[model_groups_count[model_name] != 0]\n",
    "        result[f'{model_name}_count'] = list(model_groups_count[model_name])\n\n",
    "        # mean predict and fact values\n",
    "        model_groups_mean = df_y[[model_name, y.name, 'group']].groupby('group', as_index=False).mean()\n",
    "        result[f'{model_name}_bins'] = list(model_groups_mean['group'].astype(str).dropna())\n",
    "        result[f'{model_name}'] = [\n",
    "            list(round(model_groups_mean[model_name].dropna(), 3)),\n",
    "            list(round(model_groups_mean[y.name].dropna(), 3)),\n",
    "        ]\n",
    "        nav_class = \"nav-link active\" if model_name == models[0] else \"nav-link\"\n",
    "        nav_items += f'''\n",
    "        <li class=\"nav-item\">\n",
    "            <a class=\"{nav_class}\" aria-current=\"true\" href=\"#comparison_{model_name}_{data_type}\" data-bs-toggle=\"tab\">\n",
    "            {model_name}</a>\n",
    "        </li>'''\n",
    "        tab_pane_class = \"tab-pane active\" if model_name == models[0] else \"tab-pane\"\n",
    "        tab_pane_items += f'''\n",
    "        <div class=\"{tab_pane_class}\" id=\"comparison_{model_name}_{data_type}\">\n",
    "            <div id=\"models_comparison_{model_name}_{data_type}\"></div>\n",
    "        </div>\n",
    "        '''\n",
    "    result['models_names'] = models\n",
    "    return (\n",
    "        result,\n",
    "        f'''\n",
    "    <div class=\"card text-center\">\n",
    "        <div class=\"card-header\">\n",
    "            <ul class=\"nav nav-tabs card-header-tabs text-nowrap p-3\" data-bs-tabs=\"tabs\"\n",
    "             style=\"overflow-x: auto;\">\n",
    "                {nav_items}\n",
    "            </ul>\n",
    "        </div>\n",
    "        <form class=\"card-body tab-content\">\n",
    "            {tab_pane_items}\n",
    "        </form>\n",
    "    </div>''',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_difference_comparison(\n",
    "    data_type,\n",
    "    x,\n",
    "    y,\n",
    "    main_model,\n",
    "    models_to_compare,\n",
    "    main_diff_model,\n",
    "    compare_diff_models,\n",
    "    groups_type,\n",
    "    bins,\n",
    "    start,\n",
    "    end,\n",
    "    freq,\n",
    "):\n",
    "    main_model = main_diff_model if main_diff_model else main_model\n",
    "    models_to_compare = compare_diff_models if compare_diff_models else models_to_compare\n",
    "    nav_items = ''\n",
    "    tab_pane_items = ''\n",
    "    result = {}\n",
    "    models = []\n",
    "    main_pred = main_model.predict(x)\n",
    "    try:\n",
    "        result['main_model'] = main_model.algo\n",
    "    except AttributeError:\n",
    "        result['main_model'] = main_model.__class__.__name__\n",
    "    for model in models_to_compare:\n",
    "        try:\n",
    "            model_name = model.algo\n",
    "        except AttributeError:\n",
    "            model_name = model.__class__.__name__\n",
    "        # create Dataframe to save and group values\n",
    "        y_preds = pd.DataFrame(y.copy())\n",
    "        y_preds['main_pred'] = main_pred\n",
    "        y_pred = model.predict(x)\n",
    "        model_name = f'{model_name}_1' if model_name in models else model_name\n",
    "        y_preds[model_name] = y_pred\n",
    "        models.append(model_name)\n\n",
    "        # get the difference\n",
    "        y_preds['diff_fact_model'] = y_preds[y.name] - y_preds['main_pred']\n",
    "        y_preds['diff_model_model'] = y_preds[model_name] - y_preds['main_pred']\n",
    "        y_preds['diff_groups'] = _cut_column(y_preds['diff_model_model'], groups_type, bins, start, end, freq)\n",
    "        y_preds.sort_values(by='diff_model_model', inplace=True)\n\n",
    "        # count in groups\n",
    "        main_model_count = y_preds[['diff_model_model', 'diff_groups']].groupby('diff_groups', as_index=False).count()\n",
    "        result[f'count_{model_name}'] = list(\n",
    "            main_model_count[main_model_count['diff_model_model'] != 0]['diff_model_model']\n",
    "        )\n\n",
    "        # mean predict and fact values\n",
    "        model_groups_mean = (\n",
    "            y_preds[['diff_model_model', 'diff_fact_model', 'diff_groups']]\n",
    "            .groupby('diff_groups', as_index=False)\n",
    "            .mean()\n",
    "        )\n",
    "        result[f'diff_model_{model_name}'] = list(round(model_groups_mean['diff_model_model'].dropna(), 3))\n",
    "        result[f'diff_fact_{model_name}'] = list(round(model_groups_mean['diff_fact_model'].dropna(), 3))\n",
    "        result[f'{model_name}_bins'] = list(model_groups_mean['diff_groups'].astype(str).dropna())\n",
    "        nav_class = \"nav-link active\" if model_name == models[0] else \"nav-link\"\n",
    "        nav_items += f'''\n",
    "        <li class=\"nav-item\">\n",
    "            <a class=\"{nav_class}\" aria-current=\"true\" href=\"#diff_comparison_{model_name}_{data_type}\"\n",
    "            data-bs-toggle=\"tab\">\n",
    "            {model_name}</a>\n",
    "        </li>'''\n",
    "        tab_pane_class = \"tab-pane active\" if model_name == models[0] else \"tab-pane\"\n",
    "        tab_pane_items += f'''\n",
    "        <div class=\"{tab_pane_class}\" id=\"diff_comparison_{model_name}_{data_type}\">\n",
    "            <div id=\"models_diff_comparison_{model_name}_{data_type}\"></div>\n",
    "        </div>\n",
    "        '''\n",
    "    result['models_names'] = models\n",
    "    return (\n",
    "        result,\n",
    "        f'''\n",
    "    <div class=\"card text-center\">\n",
    "        <div class=\"card-header\">\n",
    "            <ul class=\"nav nav-tabs card-header-tabs text-nowrap p-3\" data-bs-tabs=\"tabs\"\n",
    "             style=\"overflow-x: auto;\">\n",
    "                {nav_items}\n",
    "            </ul>\n",
    "        </div>\n",
    "        <form class=\"card-body tab-content\">\n",
    "            {tab_pane_items}\n",
    "        </form>\n",
    "    </div>''',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_comparison_matrix(x, y, pairs_for_matrix, bins, freq):\n",
    "    if not pairs_for_matrix:\n",
    "        return ''\n",
    "    # check if pairs is [] and then make it [[]]\n",
    "    pairs_for_matrix = [pairs_for_matrix] if len(np.array(pairs_for_matrix).shape) == 1 else pairs_for_matrix\n",
    "    nav_items = ''\n",
    "    tab_pane_items = ''\n",
    "    cm = sns.light_palette(\"Blue\", as_cmap=True)\n",
    "    i = 0\n",
    "    for pair in pairs_for_matrix:\n",
    "        # check if pair is a pair\n",
    "        if len(pair) != 2:\n",
    "            raise NotImplementedError(\n",
    "                f'Only two values is supported as a pair, now {pair} pair has {len(pair)} values.'\n",
    "            )\n",
    "        pair_df = pd.DataFrame(y)\n",
    "        models_names = []\n",
    "        for model in pair:\n",
    "            try:\n",
    "                model_name = model.algo\n",
    "            except AttributeError:\n",
    "                model_name = model.__class__.__name__\n",
    "            # predict values\n",
    "            pair_df[model_name] = model.predict(x)\n",
    "            models_names.append(model_name)\n",
    "        # create intervals with min and max values in all columns\n",
    "        _start = min(pair_df.min()) - 1\n",
    "        _end = max(pair_df.max()) + 1\n",
    "        _bins = (\n",
    "            pd.interval_range(start=_start, end=_end, freq=freq)\n",
    "            if freq\n",
    "            else pd.interval_range(start=_start, end=_end, periods=bins)\n",
    "        )\n",
    "        _bins = pd.IntervalIndex([pd.Interval(round(i.left, 2), round(i.right, 2), i.closed) for i in _bins])\n",
    "        pair_df['groups'] = _cut_column(pair_df[y.name], groups_type='cut', bins=_bins)\n",
    "        unique_gr = pair_df['groups'].unique()\n",
    "        # create empty dataframes\n",
    "        df_compare = pd.DataFrame(index=sorted(unique_gr), columns=sorted(unique_gr))\n",
    "        df_count = pd.DataFrame(index=sorted(unique_gr), columns=sorted(unique_gr))\n",
    "        # get rows where both predict values are in the interval\n",
    "        for gr in unique_gr:\n",
    "            for gr_2 in unique_gr:\n",
    "                col0 = pair_df[models_names[0]]\n",
    "                col1 = pair_df[models_names[1]]\n",
    "                df_compare.loc[gr, gr_2] = (\n",
    "                    pair_df.loc[col0.between(gr.left, gr.right) & col1.between(gr_2.left, gr_2.right), y.name].sum()\n",
    "                    / pair_df.loc[col0.between(gr.left, gr.right) & col1.between(gr_2.left, gr_2.right), y.name].count()\n",
    "                )\n",
    "                df_count.loc[gr, gr_2] = pair_df.loc[\n",
    "                    col0.between(gr.left, gr.right) & col1.between(gr_2.left, gr_2.right), y.name\n",
    "                ].count()\n",
    "        style_df = df_compare.style.background_gradient(axis=None, gmap=df_count, cmap=cm).format('{:.3f}')\n",
    "        if len(pairs_for_matrix) == 1:\n",
    "            return f'''<h5 class=\"text-center fw-light\">{models_names[0]} and {models_names[1]} comparison matrix:</h5>\n",
    "            {style_df.to_html(table_attributes='classes=\"table\"')}'''\n",
    "        else:\n",
    "            nav_class = \"nav-link active\" if i == 0 else \"nav-link\"\n",
    "            nav_items += f'''\n",
    "            <li class=\"nav-item\">\n",
    "                <a class=\"{nav_class}\" aria-current=\"true\" href=\"#comparison_matrix_{i}\" data-bs-toggle=\"tab\">\n",
    "                {models_names[0]} and {models_names[1]}</a>\n",
    "            </li>'''\n",
    "            tab_pane_class = \"tab-pane active\" if i == 0 else \"tab-pane\"\n",
    "            tab_pane_items += f'''\n",
    "            <div class=\"{tab_pane_class}\" id=\"comparison_matrix_{i}\">\n",
    "            <h5 class=\"text-center fw-light\">{models_names[0]} and {models_names[1]} comparison matrix:</h5>\n",
    "                {style_df.to_html(table_attributes='classes=\"table\"')}\n",
    "            </div>\n",
    "            '''\n",
    "        i += 1\n",
    "    return f'''\n",
    "    <div class=\"card text-center\">\n",
    "        <div class=\"card-header\">\n",
    "            <ul class=\"nav nav-tabs card-header-tabs text-nowrap p-3\" data-bs-tabs=\"tabs\"\n",
    "            style=\"overflow-x: auto;\">\n",
    "                {nav_items}\n",
    "            </ul>\n",
    "        </div>\n",
    "        <form class=\"card-body tab-content\">\n",
    "            {tab_pane_items}\n",
    "        </form>\n",
    "    </div>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cut_column(column, groups_type, bins=None, start=None, end=None, freq=None):\n",
    "    p = 0 if column.dtype == 'int64' else 2\n",
    "    # group results\n",
    "    try:\n",
    "        groups_type, bins, start, end, freq = _get_columns_params(column, groups_type, bins, start, end, freq)\n",
    "        if groups_type == 'cut':\n",
    "            return pd.cut(column, bins)\n",
    "        elif groups_type == 'qcut':\n",
    "            return pd.qcut(column, bins)\n",
    "        elif groups_type == 'freq':\n",
    "            _start = min(column) - 1 if start is None else start\n",
    "            _end = max(column) if end is None else end\n",
    "            _bins = pd.interval_range(start=_start, end=_end, freq=freq)\n",
    "            # count digits after the decimal point\n",
    "            s = str(freq)\n",
    "            p = 0 if s.isdecimal() else len(s.split('.')[1])\n",
    "            _bins = pd.IntervalIndex([pd.Interval(round(i.left, p), round(i.right, p), i.closed) for i in _bins])\n",
    "            # pd.interval_range creates big numbers, it rounds them\n",
    "            return pd.cut(column, bins=_bins)\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                f'`groups_type` = {groups_type} is not supported, must be `cut`, `qcut` or `freq`.'\n",
    "            )\n",
    "    except TypeError:\n",
    "        return column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}