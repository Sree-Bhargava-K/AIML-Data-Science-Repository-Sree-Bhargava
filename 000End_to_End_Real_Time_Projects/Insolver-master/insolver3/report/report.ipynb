{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "import builtins\n",
    "import inspect\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .presets import (\n",
    "    _create_shap,\n",
    "    _create_partial_dependence,\n",
    "    _create_dataset_description,\n",
    "    _create_pandas_profiling,\n",
    "    _create_importance_charts,\n",
    "    _create_features_description,\n",
    "    _explain_instance,\n",
    ")\n",
    "from .metrics import _create_metrics_charts, _calc_metrics\n",
    "from .comparison_presets import _create_models_comparison\n",
    "from .error_handler import error_handler\n",
    "import shutil\n",
    "import jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Report:\n",
    "    \"\"\"Combine data and model summary in one html report\n",
    "    Parameters:\n",
    "        model (InsolverBaseWrapper): A fitted model implementing `predict`.\n",
    "        task (str): Model type, supported values are `reg` and `class`.\n",
    "        X_train (pandas.DataFrame): Train data.\n",
    "        y_train (pandas.Series): Train target.\n",
    "        predicted_train (pandas.Series): Train values predicted by the model.\n",
    "        X_test (pandas.DataFrame): Test data.\n",
    "        y_test (pandas.Series): Test target.\n",
    "        predicted_test (pandas.Series): Test values predicted by the model.\n",
    "        original_dataset (pandas.Dataframe): Original dataset for creating features information.\n",
    "        shap_type (str): Type of the explainer, supported values are `tree` and `linear`.\n",
    "        explain_instance (pandas.Series): Instance to be explained using shap, lime and dice.\n",
    "        exposure_column (pandas.Series, str): Exposure column name for the gini coef and gain curve.\n",
    "        dataset_description (str): Description of the dataset set to display.\n",
    "        y_description (str): Description of the y value set to display.\n",
    "        features_description (str): Features description set to display.\n",
    "        metrics_to_calc (list): The names of the metrics to be calculated, can be `all` (all metrics will be\n",
    "            calculated), `main` or list.\n",
    "        show_parameters (bool): Show all model parameters, default value is False\n",
    "            because some models have a lot of parameters.\n",
    "        pandas_profiling (bool): Create Pandas Profiling, default value is True.\n",
    "        models_to_compare (list): Fitted models implementing `predict` for comparison.\n",
    "        comparison_metrics (list): Metrics for comparison.\n",
    "        f_groups_type (str, dict): Groups type for the `Features comparison chart`, supported values are: `cut` - bin\n",
    "            values into discrete intervals, `qcut` - quantile-based discretization function, `freq` - bins created\n",
    "            using start, end and the length of each interval. If str, all features are cut using `f_groups_type`. If\n",
    "            dict, must be {'feature': 'groups_type', 'all': 'groups_type'} where 'all' will be used for all features\n",
    "            not listed in the dict.\n",
    "        f_bins (int, dict): Bins for the `Features comparison chart`. Number of bins for `cut` and `qcut` groups_type.\n",
    "            If int, all features are cut using `f_bins`. If dict, must be {'feature': bins, 'all': 'groups_type'}\n",
    "            where 'all' will be used for all features not listed in the dict. Default value is 10.\n",
    "        f_start (float, dict): Start for the `Features comparison chart`. Start value for `freq` groups_type. If not\n",
    "            set, min(column)-1 is used. If float, all features are cut using `f_start`. If dict, must be\n",
    "            {'feature': start, 'all': 'groups_type'} where 'all' will be used for all features not listed in the dict.\n",
    "        f_end (float, dict): End for the `Features comparison chart`. End value for `freq` groups_type. If not\n",
    "            set, max(column) is used. If float, all features are cut using `f_end`. If dict, must be\n",
    "            {'feature': end, 'all': 'groups_type'} where 'all' will be used for all features not listed in the dict.\n",
    "        f_freq (float, dict): Freq for the `Features comparison chart`. The length of each interval for `freq`\n",
    "            groups_type. Default value is 1.5. If float, all features are cut using `f_freq`. If dict, must be\n",
    "            {'feature': freq, 'all': 'groups_type'} where 'all' will be used for all features not listed in the dict.\n",
    "        p_groups_type (str): Groups type for the `Predict groups chart`, supported values are: `cut` - bin\n",
    "            values into discrete intervals, `qcut` - quantile-based discretization function, `freq` - bins created\n",
    "            using start, end and the length of each interval.\n",
    "        p_bins (int): Bins for the `Predict groups chart`. Number of bins for `cut` and `qcut` groups_type. Default\n",
    "            value is 10.\n",
    "        p_start (float): Start for the `Predict groups chart`. Start value for `freq` groups_type. If not\n",
    "            set, min(column)-1 is used.\n",
    "        p_end (float): End for the `Predict groups chart`. End value for `freq` groups_type. If not\n",
    "            set, max(column) is used.\n",
    "        p_freq (float): Freq for the `Predict groups chart`. The length of each interval for `freq`\n",
    "            groups_type. Default value is 1.5.\n",
    "        d_groups_type (str): Groups type for the `Difference chart`, supported values are: `cut` - bin\n",
    "            values into discrete intervals, `qcut` - quantile-based discretization function, `freq` - bins created\n",
    "            using start, end and the length of each interval.\n",
    "        d_bins (int): Bins for the `Difference chart`. Number of bins for `cut` and `qcut` groups_type. Default\n",
    "            value is 10.\n",
    "        d_start (float): Start for the `Difference chart`. Start value for `freq` groups_type. If not set,\n",
    "            min(column)-1 is used.\n",
    "        d_end (float): End for the `Difference chart`. End value for `freq` groups_type. If not set, max(column)\n",
    "            is used.\n",
    "        d_freq (float): Freq for the `Difference chart`. The length of each interval for `freq` groups_type.\n",
    "            Default value is 1.5.\n",
    "        main_diff_model: Main difference model for the `Difference chart`.\n",
    "        compare_diff_models (list): Models for comparison with the main model for the `Difference chart`.\n",
    "        pairs_for_matrix (list): List of pairs for the `Comparison matrix`.\n",
    "        m_bins (int): Number of bins for the `Comparison matrix`.\n",
    "        m_freq (float): The length of each interval for the `Comparison matrix`. If set, m_bins won't be used.\n",
    "    Public methods:\n",
    "        to_html(path, report_name): Generates html report.\n",
    "        get_sections() Get created self.sections dict.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        task,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        original_dataset,\n",
    "        shap_type,\n",
    "        predicted_train=None,\n",
    "        predicted_test=None,\n",
    "        explain_instance=None,\n",
    "        exposure_column=None,\n",
    "        dataset_description: str = 'Add a model description to the `dataset_description` parameter.',\n",
    "        y_description: str = 'Add a y description to the `y_description` parameter.',\n",
    "        features_description=None,\n",
    "        metrics_to_calc='main',\n",
    "        models_to_compare=None,\n",
    "        comparison_metrics=None,\n",
    "        f_groups_type='cut',\n",
    "        f_bins=10,\n",
    "        f_start=None,\n",
    "        f_end=None,\n",
    "        f_freq=1.5,\n",
    "        p_groups_type='cut',\n",
    "        p_bins=10,\n",
    "        p_start=None,\n",
    "        p_end=None,\n",
    "        p_freq=1.5,\n",
    "        d_groups_type='cut',\n",
    "        d_bins=10,\n",
    "        d_start=None,\n",
    "        d_end=None,\n",
    "        d_freq=1.5,\n",
    "        main_diff_model=None,\n",
    "        compare_diff_models=None,\n",
    "        pairs_for_matrix=None,\n",
    "        m_bins=20,\n",
    "        m_freq=None,\n",
    "        show_parameters=False,\n",
    "        pandas_profiling=True,\n",
    "    ):\n",
    "        # check and save attributes\n",
    "        self.pandas_profiling = pandas_profiling\n",
    "        self.show_parameters = show_parameters\n",
    "        self.metrics_to_calc = metrics_to_calc\n",
    "        self.exposure_column = exposure_column.name if isinstance(exposure_column, pandas.Series) else exposure_column\n",
    "        self.shap_type = shap_type\n",
    "        self.dataset_description = dataset_description\n",
    "        self.y_description = y_description\n",
    "        self.features_description = features_description\n",
    "        self.model = model\n",
    "        self.models_to_compare = models_to_compare\n",
    "        self.comparison_metrics = [] if not comparison_metrics else comparison_metrics\n",
    "        self.predicted_train = (\n",
    "            pandas.Series(model.predict(X_train), index=X_train.index)\n",
    "            if not isinstance(predicted_train, pandas.Series)\n",
    "            else predicted_train\n",
    "        )\n",
    "        self.predicted_test = (\n",
    "            pandas.Series(model.predict(X_test), index=X_test.index)\n",
    "            if not isinstance(predicted_test, pandas.Series)\n",
    "            else predicted_test\n",
    "        )\n",
    "        self.explain_instance = explain_instance\n",
    "        if task in ['reg', 'class']:\n",
    "            self.task = task\n",
    "        else:\n",
    "            raise ValueError(f\"Not supported task class {task}\")\n",
    "        if (\n",
    "            isinstance(X_train, pandas.DataFrame)\n",
    "            and isinstance(X_test, pandas.DataFrame)\n",
    "            and isinstance(y_train, pandas.Series)\n",
    "            and isinstance(y_test, pandas.Series)\n",
    "            and isinstance(self.predicted_train, pandas.Series)\n",
    "            and isinstance(self.predicted_test, pandas.Series)\n",
    "            and isinstance(original_dataset, pandas.DataFrame)\n",
    "        ):\n",
    "            self.X_train = X_train\n",
    "            self.y_train = y_train\n",
    "            self.X_test = X_test\n",
    "            self.y_test = y_test\n",
    "            self.original_dataset = original_dataset\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                f\"\"\"Wrong types of input data.\n",
    "              \\rX_train {type(X_train)} must be pandas.DataFrame\n",
    "              \\ry_train {type(y_train)} must be pandas.Series\n",
    "              \\rX_test {type(X_test)} must be pandas.DataFrame\n",
    "              \\ry_test {type(y_test)} should be pandas.Series\n",
    "              \\rpredicted_train {type(self.predicted_train)} must be pandas.Series\n",
    "              \\rpredicted_test {type(self.predicted_test)} must be pandas.Series\n",
    "              \\rpredicted_test {type(original_dataset)} must be pandas.DataFrame\"\"\"\n",
    "            )\n",
    "        self._directory = ntpath.dirname(inspect.getfile(Report))\n\n",
    "        # check columns\n",
    "        if not sorted(X_train.columns.to_list()) == sorted(X_test.columns.to_list()):\n",
    "            raise KeyError(\n",
    "                f'''Columns in X_train {sorted(X_train.columns.to_list())}\n",
    "            and X_test {sorted(X_test.columns.to_list())} are not the same.'''\n",
    "            )\n",
    "        elif len(set(X_train.columns.to_list()).difference(original_dataset.columns.to_list())) > 0:\n",
    "            s = set(X_train.columns.to_list()).difference(original_dataset.columns.to_list())\n",
    "            raise KeyError(f'''Columns from X_train {s} are missing from original_dataset.''')\n\n",
    "        # check shap_type\n",
    "        if shap_type not in ['tree', 'linear']:\n",
    "            raise NotImplementedError(f'shap type {shap_type} must be \"tree\" or \"linear\".')\n",
    "        self.f_groups_type = f_groups_type\n",
    "        self.f_bins = f_bins\n",
    "        self.f_start = f_start\n",
    "        self.f_end = f_end\n",
    "        self.f_freq = f_freq\n",
    "        self.p_groups_type = p_groups_type\n",
    "        self.p_bins = p_bins\n",
    "        self.p_start = p_start\n",
    "        self.p_end = p_end\n",
    "        self.p_freq = p_freq\n",
    "        self.d_groups_type = d_groups_type\n",
    "        self.d_bins = d_bins\n",
    "        self.d_start = d_start\n",
    "        self.d_end = d_end\n",
    "        self.d_freq = d_freq\n",
    "        self.main_diff_model = main_diff_model\n",
    "        self.compare_diff_models = compare_diff_models\n",
    "        self.m_bins = m_bins\n",
    "        self.m_freq = m_freq\n",
    "        self.pairs_for_matrix = pairs_for_matrix\n\n",
    "        # create additional parameters\n",
    "        self.pbar = tqdm(total=10)\n",
    "        self.profile = None\n\n",
    "        # prepare jinja environment and template\n",
    "        templateLoader = jinja2.FileSystemLoader(searchpath=self._directory)\n",
    "        self.env = jinja2.Environment(loader=templateLoader)\n",
    "        self.template = self.env.get_template(\"report_template.html\")\n\n",
    "        # content to fill jinja template\n",
    "        self.sections = []\n",
    "    def get_sections(self):\n",
    "        return self.sections\n",
    "    def _save_dataset_section(self, path, report_name):\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating Dataset section')\n\n",
    "        # create section\n",
    "        section = [\n",
    "            {\n",
    "                'name': 'Dataset',\n",
    "                'articles': [\n",
    "                    _create_dataset_description(\n",
    "                        self.X_train,\n",
    "                        self.X_test,\n",
    "                        self.y_train,\n",
    "                        self.y_test,\n",
    "                        self.task,\n",
    "                        self.dataset_description,\n",
    "                        self.y_description,\n",
    "                        self.original_dataset,\n",
    "                    ),\n",
    "                ],\n",
    "                'icon': '<i class=\"bi bi-bricks\" width=\"24\" height=\"24\" role=\"img\"></i>',\n",
    "            }\n",
    "        ]\n\n",
    "        # create pandas profiling\n",
    "        if self.pandas_profiling:\n",
    "            self._profile_data()\n",
    "            pandas_profiling_html = _create_pandas_profiling()\n",
    "            section[0]['articles'].append(pandas_profiling_html)\n\n",
    "        # create features description article, contains specification, description and psi\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating features description article')\n",
    "        section[0]['articles'].append(\n",
    "            _create_features_description(self.X_train, self.X_test, self.original_dataset, self.features_description)\n",
    "        )\n\n",
    "        # save section\n",
    "        self.sections.append(section[0])\n",
    "        with open(f'{path}/{report_name}/dataset_section.html', 'w') as f:\n",
    "            html_ = self.template.render(sections=section, title='Dataset')\n",
    "            html_ = html_.replace('&#34;', '\"').replace('&lt;', '<').replace('&gt;', '>')\n",
    "            f.write(html_)\n",
    "    def _save_model_section(self, path, report_name):\n",
    "        # get features importance\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating features importance')\n",
    "        features_importance_footer, features_importance = self._model_features_importance()\n",
    "        # calculate train test metrics\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating train test metrics')\n",
    "        calculate_train_test_metrics = self._calculate_train_test_metrics()[1]\n",
    "        # create lift chart and gain curve\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating lift chart and gain curve')\n",
    "        metrics_footer, metrics_part = _create_metrics_charts(\n",
    "            self.X_train,\n",
    "            self.X_test,\n",
    "            self.y_train,\n",
    "            self.y_test,\n",
    "            self.predicted_train,\n",
    "            self.predicted_test,\n",
    "            self.exposure_column,\n",
    "        )\n",
    "        # create shap\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating shap')\n",
    "        shap_footer, shap_part = _create_shap(self.X_train, self.X_test, self.model, self.shap_type)\n",
    "        # create partial dependence\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_description('Creating partial dependence')\n",
    "        pdp_footer, pdp_part = _create_partial_dependence(self.X_train, self.X_test, self.model)\n",
    "        section = [\n",
    "            {\n",
    "                'name': 'Model',\n",
    "                'articles': [\n",
    "                    {\n",
    "                        'name': 'Coefficients',\n",
    "                        'parts': [\n",
    "                            f'''\n",
    "                        <div class=\"p-3 m-3 bg-light border rounded-3 fw-light\">\n",
    "                            {features_importance}{_create_importance_charts()}</div>'''\n",
    "                        ],\n",
    "                        'header': '',\n",
    "                        'footer': features_importance_footer,\n",
    "                        'icon': '<i class=\"bi bi-bar-chart-line\"></i>',\n",
    "                    },\n",
    "                    {\n",
    "                        'name': 'Metrics',\n",
    "                        'parts': [f'{calculate_train_test_metrics}{metrics_part}'],\n",
    "                        'header': '',\n",
    "                        'footer': metrics_footer,\n",
    "                        'icon': '<i class=\"bi bi-calculator\"></i>',\n",
    "                    },\n",
    "                    {\n",
    "                        'name': 'SHAP',\n",
    "                        'parts': [shap_part],\n",
    "                        'header': '',\n",
    "                        'footer': shap_footer,\n",
    "                        'icon': '<i class=\"bi bi-filter-left\"></i>',\n",
    "                    },\n",
    "                    {\n",
    "                        'name': 'Partial Dependence',\n",
    "                        'parts': [\n",
    "                            f'''\n",
    "                        <div class=\"p-3 m-3 bg-light border rounded-3 text-center fw-light\">\n",
    "                            {pdp_part}</div>'''\n",
    "                        ],\n",
    "                        'header': '',\n",
    "                        'footer': pdp_footer,\n",
    "                        'icon': '<i class=\"bi bi-graph-up\"></i>',\n",
    "                    },\n",
    "                ],\n",
    "                'icon': '<i class=\"bi bi-tools\"></i>',\n",
    "            },\n",
    "        ]\n",
    "        self.pbar.update(1)\n",
    "        if isinstance(self.explain_instance, pandas.Series):\n",
    "            self.pbar.set_description('Explaining instance')\n",
    "            section[0]['articles'].append(\n",
    "                _explain_instance(\n",
    "                    self.explain_instance, self.model, self.X_train, self.task, self.original_dataset, self.shap_type\n",
    "                )\n",
    "            )\n",
    "        # save section\n",
    "        self.sections.append(section[0])\n",
    "        with open(f'{path}/{report_name}/model_section.html', 'w') as f:\n",
    "            html_ = self.template.render(sections=section, title='Model')\n",
    "            html_ = html_.replace('&#34;', '\"').replace('&lt;', '<').replace('&gt;', '>')\n",
    "            f.write(html_)\n",
    "    def _save_comparison_section(self, path, report_name):\n",
    "        # create models comparison if model is regression\n",
    "        self.pbar.set_description('Comparing models')\n",
    "        section = [\n",
    "            _create_models_comparison(\n",
    "                self.X_train,\n",
    "                self.y_train,\n",
    "                self.X_test,\n",
    "                self.y_test,\n",
    "                self.original_dataset,\n",
    "                self.task,\n",
    "                self.models_to_compare,\n",
    "                self.comparison_metrics,\n",
    "                self.f_groups_type,\n",
    "                self.f_bins,\n",
    "                self.f_start,\n",
    "                self.f_end,\n",
    "                self.f_freq,\n",
    "                self.p_groups_type,\n",
    "                self.p_bins,\n",
    "                self.p_start,\n",
    "                self.p_end,\n",
    "                self.p_freq,\n",
    "                self.d_groups_type,\n",
    "                self.d_bins,\n",
    "                self.d_start,\n",
    "                self.d_end,\n",
    "                self.d_freq,\n",
    "                self.model,\n",
    "                self.main_diff_model,\n",
    "                self.compare_diff_models,\n",
    "                self.m_bins,\n",
    "                self.m_freq,\n",
    "                self.pairs_for_matrix,\n",
    "                classes=\"table table-striped\",\n",
    "                justify=\"center\",\n",
    "            )\n",
    "        ]\n",
    "        # save section\n",
    "        self.sections.append(section[0])\n",
    "        with open(f'{path}/{report_name}/comparison_section.html', 'w') as f:\n",
    "            html_ = self.template.render(sections=section, title='Comparison')\n",
    "            html_ = html_.replace('&#34;', '\"').replace('&lt;', '<').replace('&gt;', '>')\n",
    "            f.write(html_)\n",
    "    def _save_params_section(self, path, report_name):\n",
    "        # show all model parameters, some models have a lot of parameters, so they are not shown by default\n",
    "        self.pbar.set_description('Creating parameters')\n",
    "        section = [\n",
    "            {\n",
    "                'name': 'Parameters',\n",
    "                'articles': [\n",
    "                    {\n",
    "                        'name': 'Parameters',\n",
    "                        'parts': self._model_parameters_to_list(),\n",
    "                        'header': '',\n",
    "                        'footer': '',\n",
    "                        'icon': '<i class=\"bi bi-layout-text-sidebar-reverse\"></i>',\n",
    "                    }\n",
    "                ],\n",
    "                'icon': '<i class=\"bi bi-layout-text-sidebar-reverse\"></i>',\n",
    "            }\n",
    "        ]\n",
    "        # save section\n",
    "        self.sections.append(section[0])\n",
    "        with open(f'{path}/{report_name}/parameters_section.html', 'w') as f:\n",
    "            html_ = self.template.render(sections=section, title='Parameters')\n",
    "            html_ = html_.replace('&#34;', '\"').replace('&lt;', '<').replace('&gt;', '>')\n",
    "            f.write(html_)\n",
    "    def to_html(self, path: str = '.', report_name: str = 'report', separate_files: bool = True):\n",
    "        \"\"\"Saves prepared report to html file\n",
    "        Args:\n",
    "            path: existing location to save report\n",
    "            report_name: name of report directory\n",
    "            separate_files: flag whether to write output to separate files\n",
    "        \"\"\"\n",
    "        def _check_name(name_, path_):\n",
    "            \"\"\"Add a number to {name_} if it exists in {path_} directory\"\"\"\n",
    "            len_name = len(name_)\n",
    "            check_names = [x.strip(f'{path_}/') for x in glob.glob(f\"{path_}/*\")]\n",
    "            check_names = [\n",
    "                x for x in check_names if x.find(name_) == 0 and (x[len_name:].isnumeric() or x[len_name:] == '')\n",
    "            ]\n",
    "            name_to_check = name_\n",
    "            name_count = len(check_names)\n",
    "            while name_to_check in check_names:\n",
    "                name_to_check = name_ + str(name_count)\n",
    "                name_count += 1\n",
    "            return name_to_check\n",
    "        path = '.' if path == '' else path\n",
    "        report_name = _check_name(report_name, path)\n\n",
    "        # copy template\n",
    "        shutil.copytree(f'{self._directory}/report_template', f'{path}/{report_name}')\n",
    "        # save profile report\n",
    "        if self.pandas_profiling:\n",
    "            self.profile.to_file(f\"{path}/{report_name}/profiling_report.html\")\n",
    "        if separate_files:\n",
    "            self._save_dataset_section(path, report_name)\n",
    "            print('Dataset section is saved.')\n",
    "            self._save_model_section(path, report_name)\n",
    "            print('Model section is saved.')\n",
    "            self.pbar.update(1)\n",
    "            if self.models_to_compare and self.task == 'reg':\n",
    "                self._save_comparison_section(path, report_name)\n",
    "                print('Comparison section is saved.')\n",
    "            self.pbar.update(1)\n",
    "            if self.show_parameters:\n",
    "                self._save_params_section(path, report_name)\n",
    "                print('Parameters section is saved.')\n",
    "            else:\n",
    "                self.pbar.set_description('All done')\n",
    "        else:\n",
    "            with open(f'{path}/{report_name}/report.html', 'w') as f:\n",
    "                html_ = self.template.render(sections=self.sections, title='Insolver Report')\n",
    "                html_ = html_.replace('&#34;', '\"').replace('&lt;', '<').replace('&gt;', '>')\n",
    "                f.write(html_)\n",
    "    @error_handler(False)\n",
    "    def _profile_data(self):\n",
    "        \"\"\"Combine all data passed in __init__ method and prepares report\"\"\"\n\n",
    "        # train and test datasets into full dataset\n",
    "        data_train = self.X_train.copy()\n",
    "        data_train[self.y_train.name] = self.y_train\n",
    "        data_test = self.X_test.copy()\n",
    "        data_test[self.y_test.name] = self.y_train\n",
    "        data = data_train.append(data_test)\n",
    "        # Profiling\n",
    "        self.profile = ProfileReport(data, title='Pandas Profiling Report')\n",
    "    @error_handler(True)\n",
    "    def _model_features_importance(self):\n",
    "        \"\"\"Depend on model backend prepare features importance list.\n",
    "        Return:\n",
    "            str: html table with features sorted by importance\n",
    "        \"\"\"\n",
    "        if self.model is not None:\n",
    "            if self.model.algo == \"rf\":\n",
    "                coefs = self._get_coefs_dict(\n",
    "                    {\n",
    "                        key: value\n",
    "                        for key, value in zip(self.model.model.feature_name_, self.model.model.feature_importances_)\n",
    "                    }\n",
    "                )\n",
    "            elif self.model.algo == \"glm\":\n",
    "                coefs = self._get_coefs_dict(self.model.coef_norm())\n",
    "            elif self.model.algo == \"gbm\":\n",
    "                coefs = self._get_coefs_dict(self.model.shap(self.X_train.append(self.X_test), show=False))\n",
    "            else:\n",
    "                raise Exception(\"Unsupperted backend type {}\".format(self.model.backend))\n",
    "            coefs_head = ['relative_importance', 'scaled_importance', 'percentage']\n",
    "            model_coefs = self._create_html_table(\n",
    "                coefs_head, coefs, two_columns_table=False, classes='table table-striped', justify='left'\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(\"Model instance was not provided\")\n",
    "        return model_coefs\n",
    "    @error_handler(False)\n",
    "    def _calculate_train_test_metrics(self):\n",
    "        table_train = _calc_metrics(\n",
    "            self.y_train, self.predicted_train, self.task, self.metrics_to_calc, self.X_train, self.exposure_column\n",
    "        )\n",
    "        table_test = _calc_metrics(\n",
    "            self.y_test, self.predicted_test, self.task, self.metrics_to_calc, self.X_test, self.exposure_column\n",
    "        )\n",
    "        table = {key: [table_train.get(key, ''), table_test.get(key, '')] for key in table_train.keys()}\n",
    "        model_metrics = self._create_html_table(\n",
    "            [\"train\", \"test\"], table, two_columns_table=False, classes='table table-striped', justify='left'\n",
    "        )\n",
    "        return model_metrics\n",
    "    @error_handler(False)\n",
    "    def _model_parameters_to_list(self):\n",
    "        \"\"\"Model parameters as html tables in one list\"\"\"\n",
    "        model_parameters_list = list()\n",
    "        for table_name, table in self._get_objects_as_dicts(self.model):\n",
    "            if table:\n",
    "                model_parameters_list.append(\n",
    "                    self._create_html_table(\n",
    "                        [str(table_name)], table, two_columns_table=True, classes='table table-striped', justify='left'\n",
    "                    )[1]\n",
    "                )\n",
    "        return model_parameters_list\n",
    "    def _get_objects_as_dicts(self, obj, path='') -> list:\n",
    "        \"\"\"Method that saves any python object instances as dict.\n",
    "        Args:\n",
    "            obj (any): Any type of python object.\n",
    "            path (str): location of object inside original object.\n",
    "        Returns:\n",
    "            list: tuples like (<str: path>, <dict: object content>)\n",
    "        \"\"\"\n",
    "        def is_builtin(obj):\n",
    "            return True if obj is None else type(obj).__name__ in dir(builtins)\n",
    "        result = list()\n",
    "        if path.count('/') > 10:\n",
    "            return result\n",
    "        elif type(obj) in [list, tuple]:\n",
    "            for item in obj:\n",
    "                result.extend(self._get_objects_as_dicts(item, path=f\"{path}\"))\n",
    "        elif type(obj) in [dict]:\n",
    "            for key, value in obj.items():\n",
    "                result.extend(self._get_objects_as_dicts(value, path=f'{path}/{key}'))\n",
    "        elif not is_builtin(obj) and '__dict__' in dir(obj):\n",
    "            if obj.__dict__:\n",
    "                obj_dict = {key: value for key, value in obj.__dict__.items() if key[0] != '_'}\n",
    "                if obj_dict:\n",
    "                    result.append(\n",
    "                        (\"{}/{}\".format(path, str(obj.__class__).replace('<', '').replace('>', '')), obj_dict)\n",
    "                    )\n",
    "            result.extend(self._get_objects_as_dicts(obj.__dict__, path))\n",
    "        return result\n",
    "    @staticmethod\n",
    "    def _create_html_table(head: list, body: dict, two_columns_table: bool = False, **kwargs):\n",
    "        \"\"\"Create html table based on python dict instance\n",
    "        Args:\n",
    "            head (list): Column's names.\n",
    "            body (dict): Data for table where dict keys are index names and dict values are data.\n",
    "            two_columns_table (bool): whether to store all data in one column  or try to sparse data by columns.\n",
    "             If True body values sholud have len(body['key']) == len(head) otherwise Exception is raised.\n",
    "            **kwargs: arguments passed to DataFrame.to_html(**kwargs) method.\n",
    "        Returns:\n",
    "            str: html-code for table.\n",
    "        \"\"\"\n",
    "        def check_body(body: dict):\n",
    "            \"\"\"Check if dict values are lists and have same length\"\"\"\n",
    "            for index, value in enumerate(body.values()):\n",
    "                if index == 0:\n",
    "                    if isinstance(value, list):\n",
    "                        value_len_prev = len(value)\n",
    "                    else:\n",
    "                        return False\n",
    "                elif not (isinstance(value, list) and len(value) == value_len_prev):\n",
    "                    return False\n",
    "                value_len_prev = len(value)\n",
    "            return True\n",
    "        def check_head(head: list, body: dict):\n",
    "            \"\"\"Checks if head list have same length with body values lists.\"\"\"\n",
    "            len_body_value = len(list(body.values())[0])\n",
    "            if len_body_value != len(head):\n",
    "                raise Exception(f\"column names list length {len(head)} not equal to columns quantity {len_body_value}\")\n",
    "        if not check_body(body) or two_columns_table:\n",
    "            body = {key: [value] for key, value in body.items()}\n",
    "        check_head(head, body)\n",
    "        result_df = pandas.DataFrame(data=body.values(), columns=head, index=body.keys())\n",
    "        footer = {\n",
    "            'columns': head,\n",
    "            'data': [result_df[column].to_list() for column in result_df.columns],\n",
    "            'index': list(result_df.axes[0]),\n",
    "        }\n",
    "        return [footer, result_df.to_html(**kwargs)]\n",
    "    @staticmethod\n",
    "    def _get_coefs_dict(model_coefs: dict) -> dict:\n",
    "        \"\"\"Extern Insolver glm wraper coef table ('relative_importance')\n",
    "        with ['scaled_importance', 'percentage'] as in h2o library\n",
    "        \"\"\"\n",
    "        # create relative_importance value\n",
    "        coefs = {key: [abs(value)] for key, value in model_coefs.items()}\n",
    "        # exclude bias\n",
    "        if coefs.get('Intercept') is not None:\n",
    "            coefs.pop('Intercept', None)\n",
    "        rel_imp_max = max([x[0] for x in coefs.values()])\n",
    "        rel_imp_sum = sum([x[0] for x in coefs.values()])\n",
    "        # add scaled_importance and percentage values\n",
    "        coefs = {key: value + [value[0] / rel_imp_max, value[0] / rel_imp_sum] for key, value in coefs.items()}\n",
    "        return {key: value for key, value in sorted(coefs.items(), key=lambda x: x[1][0], reverse=True)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}