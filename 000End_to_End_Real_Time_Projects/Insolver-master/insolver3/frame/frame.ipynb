{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Type, Optional, List, Dict, Union, Any\n",
    "from numpy import dtype as numpy_dtype\n",
    "from pandas import DataFrame\n",
    "from ..model_tools import train_val_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InsolverDataFrame(DataFrame):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Any = None,\n",
    "        index: Any = None,\n",
    "        columns: Any = None,\n",
    "        dtype: Optional[numpy_dtype] = None,\n",
    "        copy: Optional[bool] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"Primary DataFrame class for Insolver. Almost the same as the pandas.DataFrame.\n",
    "        Args:\n",
    "            data (ndarray (structured or homogeneous), Iterable, dict, or pandas.DataFrame): Dict can contain\n",
    "             `pandas.Series`, arrays, constants, dataclass or list-like objects. If data is a dict, column order follows\n",
    "             insertion-order. If a dict contains `pandas.Series` which have an index defined, it is aligned by its index\n",
    "             (default=None).\n",
    "            index (pandas.Index or array-like): Index to use for resulting frame. Will default to RangeIndex if no\n",
    "             indexing information part of input data and no index provided.\n",
    "            columns (pandas.Index or array-like): Column labels to use for resulting frame when data does not have them,\n",
    "             defaulting to `pandas.RangeIndex(0, 1, 2, â€¦, n)`. If data contains column labels, will perform column\n",
    "             selection instead (default=None).\n",
    "            dtype (numpy.dtype): Data type to force. Only a single dtype is allowed. If `None`, infer (default=None).\n",
    "            copy (bool) Copy data from inputs. For dict data, the default of None behaves like `copy=True`. For\n",
    "             `pandas.DataFrame` or 2d ndarray input, the default of `None` behaves like copy=False (default=None).\n",
    "        \"\"\"\n",
    "        super(InsolverDataFrame, self).__init__(data, index, columns, dtype, copy)\n",
    "    @property\n",
    "    def _constructor(self) -> Type[\"InsolverDataFrame\"]:\n",
    "        return InsolverDataFrame\n",
    "    def get_meta_info(self) -> Dict[str, Union[str, int, List[Dict[str, Union[str, numpy_dtype]]]]]:\n",
    "        \"\"\"Gets JSON with Insolver meta information.\n",
    "        Returns:\n",
    "            dict: Meta information JSON.\n",
    "        \"\"\"\n",
    "        meta_json = {'type': 'InsolverDataFrame', 'len': self.shape[0], 'columns': list()}\n",
    "        for column in self.columns:\n",
    "            meta_json['columns'].append({'name': column, 'dtype': self[column].dtypes, 'use': 'unknown'})\n",
    "        return meta_json\n",
    "    def split_frame(\n",
    "        self,\n",
    "        val_size: float,\n",
    "        test_size: float,\n",
    "        random_state: Optional[int] = 0,\n",
    "        shuffle: bool = True,\n",
    "        stratify: Any = None,\n",
    "    ) -> List[DataFrame]:\n",
    "        \"\"\"Function for splitting dataset into train/validation/test partitions.\n",
    "        Args:\n",
    "            val_size (float): The proportion of the dataset to include in validation partition.\n",
    "            test_size (float): The proportion of the dataset to include in test partition.\n",
    "            random_state (int, optional): Random state, passed to train_test_split() from scikit-learn\n",
    "             (default=0).\n",
    "            shuffle (bool, optional): Passed to train_test_split() from scikit-learn (default=True).\n",
    "            stratify (array_like, optional): Passed to train_test_split() from scikit-learn (default=None).\n",
    "        Returns:\n",
    "            list: (train, valid, test). A list of partitions of the initial dataset.\n",
    "        \"\"\"\n",
    "        return train_val_test_split(\n",
    "            self, val_size=val_size, test_size=test_size, random_state=random_state, shuffle=shuffle, stratify=stratify\n",
    "        )\n",
    "    def sample_request(self, batch_size: int = 1) -> Dict[str, object]:\n",
    "        \"\"\"Create json request by a random sample from InsolverDataFrame\n",
    "        Args:\n",
    "            batch_size: number of random samples\n",
    "        Returns:\n",
    "            request (dict)\n",
    "        \"\"\"\n",
    "        if batch_size == 1:\n",
    "            data_str = self.sample(batch_size).iloc[0].to_json()\n",
    "        else:\n",
    "            data_str = self.sample(batch_size).to_json()\n",
    "        data = json.loads(data_str)\n",
    "        request = {'df': data}\n",
    "        return request"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}