{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:\n",
    "To filter mobile phone spam using the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: sms_spam.csv\n",
    "https://github.com/stedy/Machine-Learning-with-R-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Exploring and preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Find the distribution of target variable (Class) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Plot the distribution of target variable using histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Summary Statistics and explain insights for at least 2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prepare the data by splitting the text documents into words and also create indicator feature for frequent words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, as this the dataset which requires some Text Analytics. This might not yet come into your notice, hence giving the \n",
    "solution for the reference. This may be helpful in the future concepts.\n",
    "\n",
    "We want to find the frequencies of words in the spam and non-spam messages. The words of the messages will be model features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15585\n"
     ]
    }
   ],
   "source": [
    "#Data preparation – splitting text documents into words\n",
    "def text_process (x):\n",
    "    return x.split()\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['text'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "february\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[0])\n",
    "print(bow_transformer.get_feature_names()[8555])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4168, 15585)\n"
     ]
    }
   ],
   "source": [
    "#Data preparation – creating indicator features for frequent words\n",
    "messages_bow = bow_transformer.transform(x_train)\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create indicator features for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4168, 15585)\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(x_train)\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(messages_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1404, 15585)\n"
     ]
    }
   ],
   "source": [
    "messages_bow = bow_transformer.transform(x_test)\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "y_pred = spam_detect_model.predict(messages_tfidf)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix\n",
      "[[1222    0]\n",
      " [  80  102]]\n"
     ]
    }
   ],
   "source": [
    "print(\"confusion_matrix\")\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Measure performance for classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.94\n",
      "precision:  1.0\n",
      "recall   :  0.56\n",
      "F1 score :  0.72\n"
     ]
    }
   ],
   "source": [
    "df_table = confusion_matrix(y_test,y_pred)\n",
    "a = (df_table[0,0] + df_table[1,1]) / (df_table[0,0] + df_table[0,1] + df_table[1,0] + df_table[1,1])\n",
    "p = df_table[1,1] / (df_table[1,1] + df_table[0,1])\n",
    "r = df_table[1,1] / (df_table[1,1] + df_table[1,0])\n",
    "f = (2 * p * r) / (p + r)\n",
    "\n",
    "print(\"accuracy : \",round(a,2))\n",
    "print(\"precision: \",round(p,2))\n",
    "print(\"recall   : \",round(r,2))\n",
    "print(\"F1 score : \",round(f,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
